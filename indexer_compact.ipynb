{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import elasticsearch\n",
    "import time\n",
    "import string\n",
    "import re\n",
    "from elasticsearch import Elasticsearch, helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'name': 'BERNTA-PC',\n",
       " 'cluster_name': 'elasticsearch',\n",
       " 'cluster_uuid': 'IP06yo9vScKZA1ZTb8R9HA',\n",
       " 'version': {'number': '7.9.2',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'zip',\n",
       "  'build_hash': 'd34da0ea4a966c4e49417f2da2f244e3e97b4e6e',\n",
       "  'build_date': '2020-09-23T00:45:33.626720Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '8.6.2',\n",
       "  'minimum_wire_compatibility_version': '6.8.0',\n",
       "  'minimum_index_compatibility_version': '6.0.0-beta1'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "es = Elasticsearch()\n",
    "es.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = 'smart'\n",
    "INDEX_SETTINGS = {\n",
    "    'mappings': {\n",
    "            'properties': {\n",
    "                'abstract': {\n",
    "                    'type': 'text',\n",
    "                    'term_vector': 'yes',\n",
    "                    'analyzer': 'english'\n",
    "                },\n",
    "                'instance': {\n",
    "                    'type': 'text'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTheIndex():\n",
    "    if es.indices.exists(INDEX_NAME):\n",
    "        es.indices.delete(index=INDEX_NAME)    \n",
    "    print(es.indices.create(index=INDEX_NAME, body=INDEX_SETTINGS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#createTheIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peek(filename, size, enc='utf-8'):\n",
    "    \"\"\"\n",
    "    Print out the first X lines in the file.\n",
    "    \"\"\"\n",
    "    if size <= 0:\n",
    "        print(\"Size must be greater than zero!\")\n",
    "        return\n",
    "\n",
    "    with open(filename, encoding=enc) as f:\n",
    "        for i,line in enumerate(f):\n",
    "            if (size >= 0) and (i >= size):\n",
    "                break\n",
    "            if i == 0: # Skip top line.\n",
    "                continue\n",
    "            print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITIES_PROCESSED = None\n",
    "DEBUGGING = False # If true, only test (index) on a small subset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'at', 'into', 'and', 'on', 'such', 'not', 'an', 'there', 'as', 'their', 'was', 'are', 'it', 'these', 'with', 'is', 'for', 'if', 'of', 'but', 'no', 'that', 'will', 'a', 'then', 'to', 'the', 'by', 'in', 'or', 'they', 'this', 'be'} - !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(['a', 'an', 'and', 'are', 'as', 'at', 'be', 'but', 'by', 'for', 'if', 'in', 'into', 'is', 'it', 'no', 'not', 'of', 'on', 'or', 'such', 'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will', 'with'])\n",
    "print(stop_words, '-', string.punctuation) # Default in ElasticSearch, + punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, remove_stopwords=False):\n",
    "    text = text.replace('_', ' ').replace('-', ' ')\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # Remove punctuation stuff.\n",
    "    text = re.sub('\\s\\s+', ' ', text) # Replace consequtive whitespace with a single space.\n",
    "    if remove_stopwords:\n",
    "        return ' '.join([v for v in text.split(' ') if not v in stop_words])\n",
    "    return text\n",
    "\n",
    "def parseAbstract(data, line):\n",
    "    \"\"\"Parse a line from long_abstract.\"\"\"\n",
    "    if (line is None) or (line[0] == '#'):\n",
    "        return\n",
    "    line = line.lower().strip()[:-5].replace('/>', '>').split(' ')\n",
    "    if len(line) < 3:\n",
    "        return # Invalid line.\n",
    "    entity = preprocess(line[0][1:-1].split('/')[-1])\n",
    "    value = preprocess(' '.join(line[2:]).replace('\\\\', ''), True)\n",
    "    data.append({\n",
    "                \"_id\": entity, \n",
    "                \"_source\": {'abstract': value, 'instance': 'thing'}\n",
    "    })\n",
    "    if DEBUGGING:\n",
    "        ENTITIES_PROCESSED.add(entity) # Testing\n",
    "\n",
    "def parseType(data, line):\n",
    "    \"\"\"Parse a line from instances.\"\"\"\n",
    "    if (line is None) or (line[0] == '#'):\n",
    "        return\n",
    "    line = line.lower().strip().replace('/>', '>').split(' ')\n",
    "    if (len(line) < 3) or ('__' in line[0]):\n",
    "        return # Invalid line.\n",
    "    entity = preprocess(line[0][1:-1].split('/')[-1])\n",
    "    value = preprocess(line[2][1:-1].split('/')[-1].replace('owl#', ''))\n",
    "    data.append({\n",
    "                \"_id\": entity, \n",
    "                \"_source\": {\"doc\": {'instance': value}},\n",
    "                \"_op_type\": \"update\"\n",
    "    })\n",
    "    \n",
    "def getBulkData(data):\n",
    "    \"\"\"\n",
    "    To prevent issues when debugging,\n",
    "    we only bulk data which was indexed @ abstract.\n",
    "    \"\"\"\n",
    "    if DEBUGGING:\n",
    "        return [d for d in data if (d['_id'] in ENTITIES_PROCESSED)]\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexData(size=5000):\n",
    "    \"\"\"\n",
    "    Index the data, size = how many entities to parse at a time.\n",
    "    size should not be much bigger than 20000, due to bulk index size limitations @ elasticsearch!\n",
    "    \"\"\"\n",
    "    global ENTITIES_PROCESSED\n",
    "    ENTITIES_PROCESSED = set()\n",
    "    files = [\n",
    "        ('datasets/DBpedia/long_abstracts_en.ttl', 'utf-8'),\n",
    "        ('datasets/DBpedia/instance_types_en.ttl', 'utf-8')\n",
    "    ]\n",
    "    try:\n",
    "        files = [open(f, 'r', encoding=e) for f, e in files] # Datasets to index.\n",
    "        listAbstract, listType = [], []\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Process abstracts first! (bulk)\n",
    "        for i, line in enumerate(files[0]):\n",
    "            if i == 0: # Skip top line.\n",
    "                continue\n",
    "            parseAbstract(listAbstract, line)\n",
    "            if (len(listAbstract) > size):\n",
    "                helpers.bulk(es, listAbstract, index=INDEX_NAME, raise_on_error=False, raise_on_exception=False)\n",
    "                listAbstract.clear()\n",
    "                if DEBUGGING: # Only consider a small subset during test.\n",
    "                    break\n",
    "                \n",
    "        if len(listAbstract): # Still have some remaining items? Bulk them now.\n",
    "            helpers.bulk(es, listAbstract, index=INDEX_NAME, raise_on_error=False, raise_on_exception=False)\n",
    "            listAbstract.clear()\n",
    "            \n",
    "        print(\"Indexed abstracts.\")\n",
    "        print(\"Time Elapsed: {:.4f} sec.\".format((time.time()-start_time)))\n",
    "\n",
    "        for i, line in enumerate(files[1]):\n",
    "            if i == 0: # Skip top line.\n",
    "                continue\n",
    "            parseType(listType, line)\n",
    "            if (len(listType) > size):\n",
    "                helpers.bulk(es, getBulkData(listType), index=INDEX_NAME, raise_on_error=False, raise_on_exception=False)\n",
    "                listType.clear()\n",
    "                if DEBUGGING: # Only consider a small subset during test.\n",
    "                    break\n",
    "        \n",
    "        if len(listType):\n",
    "            helpers.bulk(es, getBulkData(listType), index=INDEX_NAME, raise_on_error=False, raise_on_exception=False)\n",
    "        \n",
    "        print(\"Finished indexing successfully!\")\n",
    "        print(\"Time Elapsed: {:.4f} sec.\".format((time.time()-start_time)))\n",
    "    except Exception as e:\n",
    "        print('Error:', e)\n",
    "        print(traceback.format_exc())\n",
    "    finally:\n",
    "        for f in files:\n",
    "            f.close()\n",
    "        listAbstract.clear()\n",
    "        listType.clear()\n",
    "        ENTITIES_PROCESSED.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Takes approx 1hr and 30 min!\n",
    "#indexData(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<http://dbpedia.org/resource/Animalia_(book)> <http://dbpedia.org/ontology/abstract> \"Animalia is an illustrated children's book by Graeme Base. It was originally published in 1986, followed by a tenth anniversary edition in 1996, and a 25th anniversary edition in 2012. Over three million copies have been sold. A special numbered and signed anniversary edition was also published in 1996, with an embossed gold jacket.\"@en .\n<http://dbpedia.org/resource/Actrius> <http://dbpedia.org/ontology/abstract> \"Actresses (Catalan: Actrius) is a 1997 Catalan language Spanish drama film produced and directed by Ventura Pons and based on the award-winning stage play E.R. by Josep Maria Benet i Jornet. The film has no male actors, with all roles played by females. The film was produced in 1996.\"@en .\n<http://dbpedia.org/resource/Alain_Connes> <http://dbpedia.org/ontology/abstract> \"Alain Connes (French: [alɛ̃ kɔn]; born 1 April 1947) is a French mathematician, currently Professor at the Collège de France, IHÉS, The Ohio State University and Vanderbilt University. He was an Invited Professor at the Conservatoire national des arts et métiers (2000).\"@en .\n<http://dbpedia.org/resource/Agricultural_science> <http://dbpedia.org/ontology/abstract> \"Agricultural science is a broad multidisciplinary field of biology that encompasses the parts of exact, natural, economic and social sciences that are used in the practice and understanding of agriculture. (Veterinary science, but not animal science, is often excluded from the definition.)\"@en .\n"
     ]
    }
   ],
   "source": [
    "peek('datasets/DBpedia/long_abstracts_en.ttl', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<http://dbpedia.org/resource/Anarchism> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Thing> .\n<http://dbpedia.org/resource/Achilles> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Thing> .\n<http://dbpedia.org/resource/Autism> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://dbpedia.org/ontology/Disease> .\n<http://dbpedia.org/resource/Alabama> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://dbpedia.org/ontology/AdministrativeRegion> .\n"
     ]
    }
   ],
   "source": [
    "peek('datasets/DBpedia/instance_types_en.ttl', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}