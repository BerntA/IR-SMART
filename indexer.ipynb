{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import traceback\n",
    "import elasticsearch\n",
    "from collections import Counter\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from elasticsearch import Elasticsearch, helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'BERNTA-PC',\n",
       " 'cluster_name': 'elasticsearch',\n",
       " 'cluster_uuid': 'IP06yo9vScKZA1ZTb8R9HA',\n",
       " 'version': {'number': '7.9.2',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'zip',\n",
       "  'build_hash': 'd34da0ea4a966c4e49417f2da2f244e3e97b4e6e',\n",
       "  'build_date': '2020-09-23T00:45:33.626720Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '8.6.2',\n",
       "  'minimum_wire_compatibility_version': '6.8.0',\n",
       "  'minimum_index_compatibility_version': '6.0.0-beta1'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch()\n",
    "es.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELDS = ['abstract', 'subject', 'instance']\n",
    "INDEX_NAME = 'fasttest'\n",
    "INDEX_SETTINGS = {\n",
    "    'mappings': {\n",
    "            'properties': {\n",
    "                'abstract': {\n",
    "                    'type': 'text',\n",
    "                    'term_vector': 'yes',\n",
    "                    'analyzer': 'english'\n",
    "                },\n",
    "                'subject': {\n",
    "                    'type': 'text',\n",
    "                    'term_vector': 'yes',\n",
    "                    'analyzer': 'english'\n",
    "                },\n",
    "                'instance': {\n",
    "                    'type': 'text',\n",
    "                    'term_vector': 'yes',\n",
    "                    'analyzer': 'english'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTheIndex():\n",
    "    if es.indices.exists(INDEX_NAME):\n",
    "        es.indices.delete(index=INDEX_NAME)    \n",
    "    es.indices.create(index=INDEX_NAME, body=INDEX_SETTINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#createTheIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words = set(stopwords.words('english'))\n",
    "#print(stop_words) # Needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peek(filename, size, enc='utf-8'):\n",
    "    \"\"\"\n",
    "    Print out the first X lines in the file.\n",
    "    \"\"\"\n",
    "    if size <= 0:\n",
    "        print(\"Size must be greater than zero!\")\n",
    "        return\n",
    "\n",
    "    with open(filename, encoding=enc) as f:\n",
    "        for i,line in enumerate(f):\n",
    "            if (size >= 0) and (i >= size):\n",
    "                break\n",
    "            if i == 0: # Skip top line.\n",
    "                continue\n",
    "            print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITIES_PROCESSED = None\n",
    "DEBUGGING = False # If true, only test (index) on a small subset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseAbstract(data, line):\n",
    "    \"\"\"Parse a line from long_abstract.\"\"\"\n",
    "    if (line is None) or (line[0] == '#'):\n",
    "        return\n",
    "    line = line.strip().replace('\"', '').replace('\\'', '').replace('@en .', '').replace('/>', '>').split(' ')\n",
    "    if len(line) < 3:\n",
    "        return # Invalid line.\n",
    "    entity = line[0][1:-1].split('/')[-1].replace('_', ' ')\n",
    "    # TODO, long abstracts might need some more preprocessing, like removing symbols except for ',.- etc.. ??\n",
    "    value = ' '.join(line[2:]).replace('\\\\', '')\n",
    "    data.append({\n",
    "                \"_id\": entity, \n",
    "                \"_source\": {'abstract': value, 'subject': '', 'instance': ''}\n",
    "    })\n",
    "    if DEBUGGING:\n",
    "        ENTITIES_PROCESSED.add(entity) # Testing\n",
    "\n",
    "def parseSubject(data, line):\n",
    "    \"\"\"Parse a line from categories.\"\"\"\n",
    "    if (line is None) or (line[0] == '#'):\n",
    "        return None, None\n",
    "    line = line.strip().replace('/>', '>').split(' ')\n",
    "    if len(line) < 3:\n",
    "        return None, None # Invalid line.\n",
    "    entity = line[0][1:-1].split('/')[-1].replace('_', ' ')\n",
    "    value = line[2][1:-1].split('/')[-1][len('Category:'):].replace('_', ' ')\n",
    "    if not entity in data:\n",
    "        data[entity] = {\n",
    "            \"_id\": entity, \n",
    "            \"_source\": {\"doc\": {'subject': value}},\n",
    "            \"_op_type\": \"update\"\n",
    "        }\n",
    "    else:\n",
    "        data[entity]['_source']['doc']['subject'] = data[entity]['_source']['doc']['subject'] + ', ' + value # Spaghetti?!\n",
    "    return entity[0].upper(), entity\n",
    "\n",
    "def parseType(data, line):\n",
    "    \"\"\"Parse a line from instances.\"\"\"\n",
    "    if (line is None) or (line[0] == '#'):\n",
    "        return\n",
    "    line = line.strip().replace('/>', '>').split(' ')\n",
    "    if len(line) < 3:\n",
    "        return # Invalid line.\n",
    "    entity = line[0][1:-1].split('/')[-1].replace('_', ' ')\n",
    "    value = line[2][1:-1].split('/')[-1].replace('owl#', '').replace('_', ' ')\n",
    "    data.append({\n",
    "                \"_id\": entity, \n",
    "                \"_source\": {\"doc\": {'instance': value}},\n",
    "                \"_op_type\": \"update\"\n",
    "    })\n",
    "    \n",
    "def getBulkData(data):\n",
    "    \"\"\"\n",
    "    To prevent issues when debugging,\n",
    "    we only bulk data which was indexed @ abstract.\n",
    "    \"\"\"\n",
    "    if DEBUGGING:\n",
    "        return [d for d in data if (d['_id'] in ENTITIES_PROCESSED)]\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexData(size=5000):\n",
    "    \"\"\"\n",
    "    Index the data, size = how many entities to parse at a time.\n",
    "    size should not be much bigger than 20000, due to bulk index size limitations @ elasticsearch!\n",
    "    \"\"\"\n",
    "    global ENTITIES_PROCESSED\n",
    "    ENTITIES_PROCESSED = set()\n",
    "    files = [\n",
    "        ('datasets/DBpedia/long_abstracts_en.ttl', 'utf-8'),\n",
    "        ('datasets/DBpedia/article_categories_en.ttl', 'utf-8'),\n",
    "        ('datasets/DBpedia/instance_types_en.ttl', 'utf-8')\n",
    "    ]\n",
    "    try:\n",
    "        files = [open(f, 'r', encoding=e) for f, e in files] # Datasets to index.\n",
    "        listAbstract, listSubject, listType = [], {}, []\n",
    "        abstractFile, categoriesFile, instancesFile = files[0], files[1], files[2]\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Process abstracts first! (bulk)\n",
    "        for i, line in enumerate(abstractFile):\n",
    "            if i == 0: # Skip top line.\n",
    "                continue\n",
    "            parseAbstract(listAbstract, line)\n",
    "            if (len(listAbstract) > size):\n",
    "                helpers.bulk(es, listAbstract, index=INDEX_NAME, raise_on_error=False, raise_on_exception=False)\n",
    "                listAbstract.clear()\n",
    "                if DEBUGGING: # Only consider a small subset during test.\n",
    "                    break\n",
    "                \n",
    "        if len(listAbstract): # Still have some remaining items? Bulk them now.\n",
    "            helpers.bulk(es, listAbstract, index=INDEX_NAME, raise_on_error=False, raise_on_exception=False)\n",
    "            listAbstract.clear()\n",
    "            \n",
    "        print(\"Indexed abstracts.\")\n",
    "        print(\"Time Elapsed: {:.4f} sec.\".format((time.time()-start_time)))\n",
    "        \n",
    "        lineB, lineC = next(categoriesFile, None), next(instancesFile, None) # Skip top lines!\n",
    "        test1, test2 = False, False\n",
    "        \n",
    "        while (lineB or lineC):\n",
    "            if DEBUGGING and test1 and test2: # Limit to a small subset during testing.\n",
    "                break\n",
    "\n",
    "            if lineB:\n",
    "                lineB = next(categoriesFile, None)\n",
    "                \n",
    "            if lineC:\n",
    "                lineC = next(instancesFile, None)\n",
    "                \n",
    "            parseType(listType, lineC)\n",
    "            currSubjectChar, ent = parseSubject(listSubject, lineB)\n",
    "            \n",
    "            # When we have at least 'size' subjects (entities)\n",
    "            # Continue to the first next char which differs from the previous entry \n",
    "            # Which triggered the underneath condition.\n",
    "            # Add further entries until the first letter in the ent. changes.\n",
    "            # Bulk the entries until that entry!\n",
    "            if (len(listSubject) > size):\n",
    "                lastSubjectChar = currSubjectChar # Find the next first letter of ent. which differs from this. Then bulk.\n",
    "                newValue = None\n",
    "                while True:\n",
    "                    if lineB:\n",
    "                        lineB = next(categoriesFile, None)                        \n",
    "                    if lineB is None:\n",
    "                        break\n",
    "                    currSubjectChar, ent = parseSubject(listSubject, lineB)\n",
    "                    if currSubjectChar and (currSubjectChar != lastSubjectChar):\n",
    "                        newValue = listSubject[ent] # This value belongs to the next 'group', save it for that group.\n",
    "                        del listSubject[ent]\n",
    "                        break\n",
    "                helpers.bulk(es, getBulkData(listSubject.values()), index=INDEX_NAME, raise_on_error=False, raise_on_exception=False)\n",
    "                listSubject.clear()\n",
    "                if newValue: # Add the newest value back again.\n",
    "                    listSubject[ent] = newValue\n",
    "                test2 = True\n",
    "\n",
    "            if (len(listType) > size):\n",
    "                helpers.bulk(es, getBulkData(listType), index=INDEX_NAME, raise_on_error=False, raise_on_exception=False)\n",
    "                listType.clear()\n",
    "                test1 = True\n",
    "\n",
    "        # If there are remaining elements left, be sure to bulk index them!\n",
    "        if len(listSubject):\n",
    "            helpers.bulk(es, getBulkData(listSubject.values()), index=INDEX_NAME, raise_on_error=False, raise_on_exception=False)\n",
    "\n",
    "        if len(listType):\n",
    "            helpers.bulk(es, getBulkData(listType), index=INDEX_NAME, raise_on_error=False, raise_on_exception=False)\n",
    "        \n",
    "        print(\"Finished indexing successfully!\")\n",
    "        print(\"Time Elapsed: {:.4f} sec.\".format((time.time()-start_time)))\n",
    "    except Exception as e:\n",
    "        print('Error:', e)\n",
    "        print(traceback.format_exc())\n",
    "    finally:\n",
    "        for f in files:\n",
    "            f.close()\n",
    "        listAbstract.clear()\n",
    "        listSubject.clear()\n",
    "        listType.clear()\n",
    "        ENTITIES_PROCESSED.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#indexData(15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<http://dbpedia.org/resource/Animalia_(book)> <http://dbpedia.org/ontology/abstract> \"Animalia is an illustrated children's book by Graeme Base. It was originally published in 1986, followed by a tenth anniversary edition in 1996, and a 25th anniversary edition in 2012. Over three million copies have been sold. A special numbered and signed anniversary edition was also published in 1996, with an embossed gold jacket.\"@en .\n",
      "<http://dbpedia.org/resource/Actrius> <http://dbpedia.org/ontology/abstract> \"Actresses (Catalan: Actrius) is a 1997 Catalan language Spanish drama film produced and directed by Ventura Pons and based on the award-winning stage play E.R. by Josep Maria Benet i Jornet. The film has no male actors, with all roles played by females. The film was produced in 1996.\"@en .\n"
     ]
    }
   ],
   "source": [
    "peek('datasets/DBpedia/long_abstracts_en.ttl', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<http://dbpedia.org/resource/A> <http://purl.org/dc/terms/subject> <http://dbpedia.org/resource/Category:ISO_basic_Latin_letters> .\n",
      "<http://dbpedia.org/resource/A> <http://purl.org/dc/terms/subject> <http://dbpedia.org/resource/Category:Vowel_letters> .\n"
     ]
    }
   ],
   "source": [
    "peek('datasets/DBpedia/article_categories_en.ttl', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<http://dbpedia.org/resource/Anarchism> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Thing> .\n",
      "<http://dbpedia.org/resource/Achilles> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Thing> .\n"
     ]
    }
   ],
   "source": [
    "peek('datasets/DBpedia/instance_types_en.ttl', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<http://dbpedia.org/resource/Autism> <http://dbpedia.org/ontology/icd10> \"F84.0\" .\n",
      "<http://dbpedia.org/resource/Autism> <http://dbpedia.org/ontology/icd9> \"299.00\" .\n"
     ]
    }
   ],
   "source": [
    "peek('datasets/DBpedia/mappingbased_literals_en.ttl', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<http://dbpedia.org/resource/Anarchism> <http://www.w3.org/2000/01/rdf-schema#seeAlso> <http://dbpedia.org/resource/Anarchist_terminology> .\n",
      "<http://dbpedia.org/resource/Anarchism> <http://www.w3.org/2000/01/rdf-schema#seeAlso> <http://dbpedia.org/resource/Anarchism> .\n"
     ]
    }
   ],
   "source": [
    "peek('datasets/DBpedia/mappingbased_objects_en.ttl', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 149,\n",
       " 'timed_out': False,\n",
       " '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0},\n",
       " 'hits': {'total': {'value': 1227, 'relation': 'eq'},\n",
       "  'max_score': 15.82955,\n",
       "  'hits': [{'_index': 'fasttest',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'Chinese pond heron',\n",
       "    '_score': 15.82955,\n",
       "    '_source': {'abstract': 'The Chinese pond heron (Ardeola bacchus) is an East Asian freshwater bird of the heron family, (Ardeidae). It is one of six species of birds known as pond herons (genus Ardeola). It is parapatric (or nearly so) with the Indian pond heron (A. grayii) to the west and the Javan pond heron (A. speciosa) to the south, and these three are presumed to form a superspecies. As a group they are variously affiliated with the squacco heron (A. ralloides) or the Malagasy pond heron (A. idae). As of mid-2011 there are no published molecular analyses of pond heron interrelationships and osteological data is likewise not analyzed for all relevant comparison taxa.',\n",
       "     'subject': 'Ardeola, Herons, Birds of China, Birds of East Asia, Animals described in 1855',\n",
       "     'instance': 'Bird'}},\n",
       "   {'_index': 'fasttest',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'Rufous-bellied heron',\n",
       "    '_score': 15.770472,\n",
       "    '_source': {'abstract': 'The rufous-bellied heron (Ardeola rufiventris) is a species of heron in the genus Ardeola, the pond herons, of the family Ardeidae.',\n",
       "     'subject': 'Ardeola, Animals described in 1851',\n",
       "     'instance': 'Bird'}},\n",
       "   {'_index': 'fasttest',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'Herons fountain',\n",
       "    '_score': 15.732068,\n",
       "    '_source': {'abstract': 'Herons fountain is a hydraulic machine invented by the 1st century AD inventor, mathematician, and physicist Heron, also known as Heron of Alexandria. Heron studied the pressure of air and steam, described the first steam engine, and built toys that would spurt water, one of them known as Herons fountain. Various versions of Herons fountain are used today in physics classes as a demonstration of principles of hydraulics and pneumatics.',\n",
       "     'subject': '',\n",
       "     'instance': ''}},\n",
       "   {'_index': 'fasttest',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'Bournes heron',\n",
       "    '_score': 15.529456,\n",
       "    '_source': {'abstract': 'Bournes heron (Ardea purpurea bournei), also known as the Cape Verde heron, Cape Verde purple heron or Santiago heron, or locally in Portuguese as the garça vermelha, is an endangered subspecies of the purple heron that is endemic to the Cape Verde archipelago, in the Atlantic Ocean off the coast of West Africa. It is sometimes considered a full species, Ardea bournei.',\n",
       "     'subject': '',\n",
       "     'instance': ''}},\n",
       "   {'_index': 'fasttest',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'Yellow-crowned night heron',\n",
       "    '_score': 15.44691,\n",
       "    '_source': {'abstract': 'The yellow-crowned night heron (Nyctanassa violacea, formerly in the genus Nycticorax), is one of two species of night herons found in the Americas, the other one being the black-crowned night heron. It is known as the Bihoreau Violacé in French and the Pedrete Corona Clara in Spanish. A related heron, the Bermuda night heron, was endemic to Bermuda, but became extinct following human colonisation.',\n",
       "     'subject': 'Nycticorax, Wading birds, Birds of the United States, Birds of Puerto Rico, Natural history of Bermuda, Birds of Bermuda, Birds of Trinidad and Tobago, Birds of North America, Birds of Central America, Birds of Canada, Birds of the Caribbean, Birds of South America, Articles containing video clips',\n",
       "     'instance': 'Bird'}},\n",
       "   {'_index': 'fasttest',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'Malayan night heron',\n",
       "    '_score': 15.35386,\n",
       "    '_source': {'abstract': 'The Malayan night heron (Gorsachius melanolophus), also known as Malaysian night heron and tiger bittern, is a medium-sized heron. It is distributed in southern and eastern Asia.',\n",
       "     'subject': 'Gorsachius, Herons, Birds of Asia, Birds of China, Birds of India, Birds of the Philippines, Birds of Taiwan',\n",
       "     'instance': 'Bird'}},\n",
       "   {'_index': 'fasttest',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'Heron Lake Township, Jackson County, Minnesota',\n",
       "    '_score': 15.219837,\n",
       "    '_source': {'abstract': 'Heron Lake Township is a township in Jackson County, Minnesota, United States. The population was 401 at the 2000 census. Heron Lake Township was organized in 1870, and named for Heron Lake.',\n",
       "     'subject': 'Townships in Jackson County, Minnesota, Townships in Minnesota',\n",
       "     'instance': 'Town'}},\n",
       "   {'_index': 'fasttest',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'Heronry',\n",
       "    '_score': 15.189329,\n",
       "    '_source': {'abstract': 'A heronry, sometimes called a heron rookery, is a breeding ground for herons.',\n",
       "     'subject': 'Herons',\n",
       "     'instance': ''}},\n",
       "   {'_index': 'fasttest',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'Black-crowned night heron',\n",
       "    '_score': 15.135948,\n",
       "    '_source': {'abstract': 'The black-crowned night heron (Nycticorax nycticorax), commonly abbreviated to just night heron in Eurasia, is a medium-sized heron found throughout a large part of the world, except in the coldest regions and Australasia (where it is replaced by the closely related rufous night heron, with which it has hybridized in the area of contact).',\n",
       "     'subject': '',\n",
       "     'instance': 'Bird'}},\n",
       "   {'_index': 'fasttest',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'Malagasy pond heron',\n",
       "    '_score': 15.125318,\n",
       "    '_source': {'abstract': 'The Malagasy pond heron (Ardeola idae) is a species of heron belonging to the Ardeidae family. They are primarily seen in the outer islands of the Seychelles, Madagascar and countries on the east coast of Africa such as Kenya, Tanzania and Uganda. Being endemic to Madagascar, this species is often referred to as the Madagascar pond heron or Madagascar squacco heron. The estimated population of this heron is thought to number 2,000–6,000 individuals, with only 1,300–4,000 being mature enough for reproductive activities.',\n",
       "     'subject': 'Ardeola, Birds of Mayotte, Animals described in 1860, Herons',\n",
       "     'instance': 'Bird'}}]}}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.search(index=INDEX_NAME, body={'query': {'match': {'abstract': 'heron'}}}, _source=True, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4931948 abstracts\n",
    "# 850298+ cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'fasttest',\n",
       " '_type': '_doc',\n",
       " '_id': 'Acquire',\n",
       " '_version': 3,\n",
       " 'found': True,\n",
       " 'took': 115,\n",
       " 'term_vectors': {'instance': {'field_statistics': {'sum_doc_freq': 4703524,\n",
       "    'doc_count': 4700543,\n",
       "    'sum_ttf': 4703524},\n",
       "   'terms': {'game': {'term_freq': 1}}},\n",
       "  'subject': {'field_statistics': {'sum_doc_freq': 51470334,\n",
       "    'doc_count': 4757672,\n",
       "    'sum_ttf': 73561889},\n",
       "   'terms': {'1962': {'term_freq': 1},\n",
       "    '3m': {'term_freq': 1},\n",
       "    'avalon': {'term_freq': 1},\n",
       "    'board': {'term_freq': 3},\n",
       "    'bookshelf': {'term_freq': 1},\n",
       "    'econom': {'term_freq': 1},\n",
       "    'game': {'term_freq': 7},\n",
       "    'hill': {'term_freq': 1},\n",
       "    'introduc': {'term_freq': 1},\n",
       "    'lai': {'term_freq': 1},\n",
       "    'multiplay': {'term_freq': 1},\n",
       "    'sackson': {'term_freq': 1},\n",
       "    'sid': {'term_freq': 1},\n",
       "    'simul': {'term_freq': 1},\n",
       "    'tile': {'term_freq': 1}}},\n",
       "  'abstract': {'field_statistics': {'sum_doc_freq': 304406661,\n",
       "    'doc_count': 7065416,\n",
       "    'sum_ttf': 401041953},\n",
       "   'terms': {'1962': {'term_freq': 1},\n",
       "    '1990': {'term_freq': 1},\n",
       "    '3m': {'term_freq': 1},\n",
       "    'acquir': {'term_freq': 3},\n",
       "    'actual': {'term_freq': 1},\n",
       "    'again': {'term_freq': 1},\n",
       "    'all': {'term_freq': 1},\n",
       "    'avalon': {'term_freq': 1},\n",
       "    'base': {'term_freq': 1},\n",
       "    'board': {'term_freq': 1},\n",
       "    'bookshelf': {'term_freq': 1},\n",
       "    'brand': {'term_freq': 1},\n",
       "    'chain': {'term_freq': 7},\n",
       "    'compani': {'term_freq': 1},\n",
       "    'corpor': {'term_freq': 1},\n",
       "    'current': {'term_freq': 1},\n",
       "    'design': {'term_freq': 1},\n",
       "    'determin': {'term_freq': 1},\n",
       "    'develop': {'term_freq': 1},\n",
       "    'earn': {'term_freq': 2},\n",
       "    'edit': {'term_freq': 1},\n",
       "    'end': {'term_freq': 1},\n",
       "    'game': {'term_freq': 7},\n",
       "    'gameplai': {'term_freq': 1},\n",
       "    'gener': {'term_freq': 1},\n",
       "    'ha': {'term_freq': 1},\n",
       "    'hasbro': {'term_freq': 2},\n",
       "    'hill': {'term_freq': 1},\n",
       "    'hotel': {'term_freq': 4},\n",
       "    'invest': {'term_freq': 1},\n",
       "    'larger': {'term_freq': 1},\n",
       "    'liquid': {'term_freq': 1},\n",
       "    'merg': {'term_freq': 1},\n",
       "    'monei': {'term_freq': 3},\n",
       "    'most': {'term_freq': 3},\n",
       "    'object': {'term_freq': 1},\n",
       "    'onc': {'term_freq': 1},\n",
       "    'order': {'term_freq': 1},\n",
       "    'origin': {'term_freq': 1},\n",
       "    'own': {'term_freq': 1},\n",
       "    'part': {'term_freq': 1},\n",
       "    'player': {'term_freq': 4},\n",
       "    'publish': {'term_freq': 2},\n",
       "    'replac': {'term_freq': 1},\n",
       "    'sackson': {'term_freq': 1},\n",
       "    'seri': {'term_freq': 1},\n",
       "    'sid': {'term_freq': 1},\n",
       "    'size': {'term_freq': 1},\n",
       "    'stock': {'term_freq': 2},\n",
       "    'theme': {'term_freq': 1},\n",
       "    'though': {'term_freq': 1},\n",
       "    'unchang': {'term_freq': 1},\n",
       "    'under': {'term_freq': 1},\n",
       "    'version': {'term_freq': 1},\n",
       "    'were': {'term_freq': 1},\n",
       "    'when': {'term_freq': 1},\n",
       "    'which': {'term_freq': 2}}}}}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.termvectors(index=INDEX_NAME, id='Acquire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
