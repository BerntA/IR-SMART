{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import elasticsearch\n",
    "import string\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "from elasticsearch import Elasticsearch\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_TRAIN_FILEPATH = 'datasets\\DBpedia\\smarttask_dbpedia_train.json'\n",
    "QUERY_TEST_FILEPATH = 'datasets\\DBpedia\\smarttask_dbpedia_test_questions.json'\n",
    "INDEX_NAME = 'smart'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no', 'as', 'or', 'are', 'with', 'is', 'this', 'not', 'and', 'at', 'their', 'in', 'an', 'will', 'to', 'a', 'the', 'it', 'but', 'such', 'there', 'they', 'was', 'these', 'for', 'into', 'of', 'be', 'on', 'then', 'by', 'if', 'that'}\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(['a', 'an', 'and', 'are', 'as', 'at', 'be', 'but', 'by', 'for', 'if', 'in', 'into', 'is', 'it', 'no', 'not', 'of', 'on', 'or', 'such', 'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will', 'with'])\n",
    "print(stop_words) # Default in ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \"\"\"Preprocess some query, lower, remove punctuation stuff, stopwords, etc.\"\"\"\n",
    "    text = text.strip().lower()\n",
    "    text = text.replace('_', ' ').replace('-', ' ')\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # Remove punctuation stuff.\n",
    "    text = re.sub('\\s\\s+', ' ', text).split(' ') # Replace consequtive whitespace with a single space.\n",
    "    return ' '.join([v for v in text if not v in stop_words]).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec - Convert GloVe to Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = datapath(os.getcwd()+'/datasets/gensim/gensim.6B.100d.txt')\n",
    "def convertGloveToGensim(target, output):\n",
    "    _ = glove2word2vec(datapath(os.getcwd()+target), datapath(os.getcwd()+output))\n",
    "#convertGloveToGensim('/datasets/glove/glove.6B.100d.txt', '/datasets/gensim/gensim.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'BERNTA-PC',\n",
       " 'cluster_name': 'elasticsearch',\n",
       " 'cluster_uuid': 'IP06yo9vScKZA1ZTb8R9HA',\n",
       " 'version': {'number': '7.9.2',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'zip',\n",
       "  'build_hash': 'd34da0ea4a966c4e49417f2da2f244e3e97b4e6e',\n",
       "  'build_date': '2020-09-23T00:45:33.626720Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '8.6.2',\n",
       "  'minimum_wire_compatibility_version': '6.8.0',\n",
       "  'minimum_index_compatibility_version': '6.0.0-beta1'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch()\n",
    "es.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs: 4926217\n"
     ]
    }
   ],
   "source": [
    "es.indices.refresh(INDEX_NAME)\n",
    "count = es.cat.count(INDEX_NAME, params={\"format\": \"json\"})\n",
    "print('Docs:', int(count[0]['count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DOCS = int(count[0]['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_queries(filepath):\n",
    "    \"\"\"\n",
    "    Load training queries from a file. \n",
    "    Returns a dictoinary with queryID as key and corresponding query, category and type.\n",
    "    \"\"\"\n",
    "    query_dicts = {}\n",
    "    queries = None\n",
    "    with open(filepath, \"r\") as f:\n",
    "        queries = f.read()\n",
    "    \n",
    "    for query in json.loads(queries):\n",
    "        try:\n",
    "            qID, qText, qCat, qType = query[\"id\"].lower(), query[\"question\"].lower(), query[\"category\"].lower(), ' '.join(query[\"type\"]).lower()\n",
    "            if not 'dbo:' in qType: # Skip queries without a dbo: type.\n",
    "                continue\n",
    "            query_dicts[qID] = {\"query\": preprocess(qText), \"category\": qCat, \"type\": qType.replace('dbo:', '')}\n",
    "        except Exception as e:\n",
    "            # print(\"Query: {}\\n\\tThrew an exception: {}\\n\".format(query, e))\n",
    "            continue\n",
    "    return query_dicts\n",
    "\n",
    "def load_test_queries(filepath):\n",
    "    \"\"\"\n",
    "    Load test queries from a file.\n",
    "    Returns a dictionary with queryID as key, and corresponding query as a string.\n",
    "    \"\"\"\n",
    "    query_dicts = {}\n",
    "    queries = None\n",
    "    with open(filepath, \"r\") as f:\n",
    "        queries = f.read()\n",
    "    \n",
    "    for query in json.loads(queries):\n",
    "        try:\n",
    "            query_dicts[query[\"id\"].lower()] = {\"query\": preprocess(query[\"question\"].lower())}\n",
    "        except Exception as e:\n",
    "            # print(\"Query: {}\\n\\tThrew an exception: {}\\n\".format(query, e))\n",
    "            continue\n",
    "    return query_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training queries: 9557 \n",
      "\tExample key 'dbpedia_17655' returns: {'query': 'what town birthplace joseph greenberg', 'category': 'resource', 'type': 'city settlement populatedplace place location'}\n",
      "# test queries: 4369 \n",
      "\tExample key 'dbpedia_21099' contain: {'query': 'under which president did some politicians live kensington'}\n"
     ]
    }
   ],
   "source": [
    "training_queries = load_train_queries(QUERY_TRAIN_FILEPATH)\n",
    "test_queries = load_test_queries(QUERY_TEST_FILEPATH)\n",
    "\n",
    "print(\"# training queries:\", len(training_queries), \"\\n\\tExample key 'dbpedia_17655' returns:\", training_queries['dbpedia_17655'])\n",
    "print(\"# test queries:\", len(test_queries), \"\\n\\tExample key 'dbpedia_21099' contain:\", test_queries['dbpedia_21099'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache analyze query\n",
    "For each train / test query -> cache the respective analyze query terms.\n",
    "This will speed up the evaluation later.\n",
    "#### This will take 2-5 minutes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_query(es, query, index=INDEX_NAME):\n",
    "    \"\"\"Analyzes a query with respect to the relevant index. \n",
    "    \n",
    "    Arguments:\n",
    "        es: Elasticsearch object instance.\n",
    "        query: String of query terms.\n",
    "        index: Name of the index with respect to which the query is analyzed.  \n",
    "    \n",
    "    Returns:\n",
    "        A list of query terms that exist in the abstract field among the documents in the index. \n",
    "    \"\"\"\n",
    "    tokens = es.indices.analyze(index=index, body={'text': query})['tokens']\n",
    "    query_terms = []\n",
    "    for t in sorted(tokens, key=lambda x: x['position']):\n",
    "        ## Use a boolean query to find at least one document that contains the term.\n",
    "        hits = es.search(index=index, body={'query': {'match': {'abstract': t['token']}}}, \n",
    "                                   _source=False, size=1).get('hits', {}).get('hits', {})\n",
    "        doc_id = hits[0]['_id'] if len(hits) > 0 else None\n",
    "        if doc_id is None:\n",
    "            continue\n",
    "        query_terms.append(t['token'])\n",
    "    return query_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 151.08664178848267\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for qId, queryObject in training_queries.items():\n",
    "    training_queries[qId]['analyzed'] = analyze_query(es, queryObject['query'], INDEX_NAME)\n",
    "    \n",
    "for qId, queryObject in test_queries.items():\n",
    "    test_queries[qId]['analyzed'] = analyze_query(es, queryObject['query'], INDEX_NAME)\n",
    "    \n",
    "print(\"Time Elapsed:\", (time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'town', 'birthplace', 'joseph', 'greenberg']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_queries['dbpedia_17655']['analyzed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load evaluation types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDBPediaTypes():\n",
    "    kv = {}\n",
    "    max_depth = 0\n",
    "    with open('./evaluation/dbpedia/dbpedia_types.tsv', 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i == 0: # Skip header\n",
    "                continue\n",
    "            line = line.strip().lower().split('\\t')\n",
    "            if len(line) != 3:\n",
    "                continue\n",
    "            type_name, depth, parent_type = line[0].split(':')[-1], int(line[1]), line[-1].split(':')[-1]\n",
    "            if (len(type_name) == 0) or (len(parent_type) == 0):\n",
    "                continue\n",
    "            kv[type_name] = {'depth':depth, 'parent':parent_type}\n",
    "            max_depth = max(depth, max_depth)\n",
    "    return kv, max_depth\n",
    "\n",
    "def getTypeHierarchy(kv, items, target):\n",
    "    if not target in kv:\n",
    "        return\n",
    "    items.append(target)\n",
    "    getTypeHierarchy(kv, items, kv[target]['parent'])\n",
    "\n",
    "def buildDBPediaTypeHierarchy(kv, target, reverse=True):\n",
    "    items = [] # List of types, representing the hierarchy of the types related to the target.\n",
    "    getTypeHierarchy(kv, items, target)\n",
    "    if reverse:\n",
    "        return items[::-1] # Reverse the order to return the correct hierarchy where the first item = top level.\n",
    "    return items\n",
    "\n",
    "def cacheDBPediaPaths():\n",
    "    \"\"\"Simplify Evaluation Path Computations\"\"\"\n",
    "    for k in type_hierarchy.keys():\n",
    "        type_hierarchy[k]['path'] = buildDBPediaTypeHierarchy(type_hierarchy, k, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['basketballleague', 'naturalevent', 'province', 'lunarcrater'] Max Depth 7\n"
     ]
    }
   ],
   "source": [
    "type_hierarchy, max_depth = loadDBPediaTypes()\n",
    "print(list(type_hierarchy.keys())[:4], 'Max Depth', max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['work', 'writtenwork', 'comic']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buildDBPediaTypeHierarchy(type_hierarchy, 'comic') # Example hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 0.002000093460083008\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "cacheDBPediaPaths()\n",
    "print(\"Time Elapsed:\", (time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Retrieval\n",
    "Implements Okapi BM25, uses the Elastic search inbuilt implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def internal_BM25(query, k = 100, field = 'abstract', index = INDEX_NAME):\n",
    "    \"\"\"\n",
    "    Perform baseline retrieval on a index using the inbuilt BM25 index\n",
    "\n",
    "    Arguments:\n",
    "        index: string\n",
    "        query: string, space separated terms\n",
    "        k: integer\n",
    "    \n",
    "    Returns:\n",
    "        List of k first entity IDs(string)\n",
    "    \"\"\"\n",
    "    hits = es.search(index=index, body={'query': {'match': {field: query}}}, _source=False, size=k).get('hits', {}).get('hits', {})\n",
    "    hits_ids = [obj['_id'] for obj in hits]\n",
    "    hits_types = [es.get(index=index, id=doc)[\"_source\"].get(\"instance\", \"thing\") for doc in hits_ids]\n",
    "    return Counter([obj for obj in hits_types if len(obj) > 0]).most_common()\n",
    "    \n",
    "def internal_BM25_score(query, k = 100, field = 'abstract', index = INDEX_NAME):\n",
    "    \"\"\"\n",
    "    Perform baseline retrieval on a index using the inbuilt BM25 index\n",
    "\n",
    "    Arguments:\n",
    "        index: string\n",
    "        query: string, space separated terms\n",
    "        k: integer\n",
    "    \n",
    "    Returns:\n",
    "        List of k first entity IDs(string), and corresponding score(double)\n",
    "    \"\"\"\n",
    "    hits = es.search(index=index, body={'query': {'match': {field: query}}}, _source=False, size=k).get('hits', {}).get('hits', {})\n",
    "    hits.sort(key = lambda x: x['_score'], reverse=True)\n",
    "    return {obj['_id']:obj['_score'] for obj in hits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('thing', 50),\n",
       " ('person', 21),\n",
       " ('organisation', 9),\n",
       " ('officeholder', 4),\n",
       " ('governmentagency', 3),\n",
       " ('academicjournal', 2),\n",
       " ('politician', 2),\n",
       " ('politicalparty', 2),\n",
       " ('non profitorganisation', 2),\n",
       " ('company', 1),\n",
       " ('saint', 1),\n",
       " ('museum', 1),\n",
       " ('writer', 1),\n",
       " ('ambassador', 1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "internal_BM25(\"civil rights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'leadership conference on civil and human rights': 14.634237,\n",
       " 'civil rights commission puerto rico': 14.519391,\n",
       " 'lawyers committee for civil rights under law': 14.449045,\n",
       " 'chicano movement': 14.209293,\n",
       " 'civil rights act': 14.079039}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "internal_BM25_score(\"civil rights\", k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_baseline(es, amount=0, index=INDEX_NAME):\n",
    "    \"\"\"\n",
    "    Evaluate the BM25 baseline on our train queries.\n",
    "    \"\"\"\n",
    "    progress, N = 0, len(training_queries)\n",
    "    results = {}\n",
    "    for qId, queryObject in training_queries.items():\n",
    "        query = queryObject['analyzed']\n",
    "        hits = es.search(index=index, _source=True, size=10,\n",
    "            body={\"query\": {\"bool\": {\"must\": {\"match\": {\"abstract\": ' '.join(query)}}, \"must_not\": {\"match\": {\"instance\": \"thing\"}}}}}\n",
    "        )['hits']['hits']\n",
    "        hits_types = [obj['_source']['instance'] for obj in hits]\n",
    "        results[qId] = {\n",
    "            'type': hits_types,\n",
    "            'category': 'resource',\n",
    "            'match': max([0] + [(1 if (t in queryObject['type']) else 0) for t in hits_types]) # Yes / No was there an explicit match?\n",
    "        }\n",
    "\n",
    "        progress += 1\n",
    "        if (progress % 50) == 0:\n",
    "            print('Progress - {}/{} queries handled.'.format(progress, N))\n",
    "\n",
    "        if amount and (progress >= amount):\n",
    "            break\n",
    "\n",
    "    return results\n",
    "\n",
    "def tokens_to_vec(tokens, model):\n",
    "    \"\"\"\n",
    "    Convert a list of tokens to some word 2 vec representation which \n",
    "    conforms to our model.\n",
    "    \"\"\"\n",
    "    size = model.wv.vectors.shape[1]\n",
    "    if len(tokens) == 0:\n",
    "        return np.zeros(size)        \n",
    "    embeddings = []\n",
    "    for v in tokens:\n",
    "        embeddings.append((model.wv.word_vec(v) if (v in model.wv.vocab) else np.random.rand(size)))\n",
    "    return np.mean(embeddings, axis=0)\n",
    "\n",
    "def evaluate_advanced(es, model, k=1000, amount=0, index=INDEX_NAME):\n",
    "    \"\"\"\n",
    "    Evaluate our advanced method, re-rank the documents using word2vec.\n",
    "    We are using pre-trained embeddings. Convert each query and related doc to word2vec format,\n",
    "    compare the similarity and re-rank the entries.\n",
    "    \"\"\"\n",
    "    progress, N = 0, len(training_queries)\n",
    "    results = {}\n",
    "    for qId, queryObject in training_queries.items():\n",
    "        query = queryObject['analyzed']\n",
    "        hits = es.search(index=index, _source=True, size=k, \n",
    "            body={\"query\": {\"bool\": {\"must\": {\"match\": {\"abstract\": ' '.join(query)}}, \"must_not\": {\"match\": {\"instance\": \"thing\"}}}}}\n",
    "        )['hits']['hits']\n",
    "        queryEmbedding = tokens_to_vec(query, model).reshape(1, -1)\n",
    "        rerank = []\n",
    "        for obj in hits:\n",
    "            docEmbedding = tokens_to_vec(obj['_source']['abstract'].split(), model).reshape(1, -1)\n",
    "            sim = cosine_similarity(queryEmbedding, docEmbedding).item()\n",
    "            rerank.append((obj['_source']['instance'], sim))\n",
    "            \n",
    "        rerank.sort(key=lambda x:x[-1], reverse=True) # Re-rank the initial hits using our word2vec mdl.\n",
    "        results[qId] = {\n",
    "            'type': [v for v,_ in rerank[:10]],\n",
    "            'category': 'resource',\n",
    "            'match': max([0] + [(1 if (t in queryObject['type']) else 0) for t,_ in rerank[:10]]) # Yes / No was there an explicit match?\n",
    "        }\n",
    "\n",
    "        progress += 1\n",
    "        if (progress % 50) == 0:\n",
    "            print('Progress - {}/{} queries handled.'.format(progress, N))\n",
    "\n",
    "        if amount and (progress >= amount):\n",
    "            break\n",
    "\n",
    "    return results\n",
    "\n",
    "def evaluate_simple(es, k=1000, amount=0, index=INDEX_NAME):\n",
    "    \"\"\"\n",
    "    Evaluate X documents per query and re-arange them based on relevance -> check how their type matches up \n",
    "    against the wanted type. Check the distance from the wanted type if they are on the same line, otherwise set it to relevancy 0 (lowest)\n",
    "    Highest = max depth in the hierarchy!\n",
    "    \"\"\"\n",
    "    progress, N = 0, len(training_queries)\n",
    "    results = {}\n",
    "    for qId, queryObject in training_queries.items():\n",
    "        type_relevancy = {}\n",
    "        for typ in queryObject['type'].split(' '):\n",
    "            if not typ in type_hierarchy:\n",
    "                continue\n",
    "            hierarchy = buildDBPediaTypeHierarchy(type_hierarchy, typ)\n",
    "            for v in hierarchy:\n",
    "                type_relevancy[v] = 1 # Relevant, its in the same hierarchy but in a diff pos.            \n",
    "\n",
    "        for typ in queryObject['type'].split(' '):\n",
    "            type_relevancy[typ] = 2 # This is the type we want. Give it the highest weight.\n",
    "            \n",
    "        if len(type_relevancy) == 0:\n",
    "            continue\n",
    "\n",
    "        query = queryObject['analyzed']\n",
    "        hits = es.search(index=index, _source=True, size=k, \n",
    "            body={\"query\": {\"bool\": {\"must\": {\"match\": {\"abstract\": ' '.join(query)}}, \"must_not\": {\"match\": {\"instance\": \"thing\"}}}}}\n",
    "        )['hits']['hits']\n",
    "\n",
    "        rerank = []\n",
    "        for obj in hits:\n",
    "            instanceType = obj['_source']['instance']\n",
    "            if not instanceType in type_hierarchy:\n",
    "                rerank.append((instanceType, 0))\n",
    "                continue\n",
    "            if instanceType in type_relevancy:                \n",
    "                rerank.append((instanceType, type_relevancy[instanceType]))\n",
    "                continue                \n",
    "            weight = buildDBPediaTypeHierarchy(type_hierarchy, instanceType)\n",
    "            weight = [(1 if (t in type_relevancy) else 0) for t in weight] + [0]\n",
    "            rerank.append((instanceType, max(weight)))\n",
    "\n",
    "        rerank.sort(key=lambda x:x[-1], reverse=True) # Re-rank the initial hits based on their relevancy.\n",
    "        results[qId] = {\n",
    "            'type': [v for v,_ in rerank[:10]],\n",
    "            'category': 'resource',\n",
    "            'match': max([0] + [(1 if (t in queryObject['type']) else 0) for t,_ in rerank[:10]]) # Yes / No was there an explicit match?\n",
    "        }\n",
    "\n",
    "        progress += 1\n",
    "        if (progress % 50) == 0:\n",
    "            print('Progress - {}/{} queries handled.'.format(progress, N))\n",
    "\n",
    "        if amount and (progress >= amount):\n",
    "            break\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg(gains, k=5):\n",
    "    \"\"\"\n",
    "    Computes DCG for a given ranking.\n",
    "    Traditional DCG formula: DCG_k = sum_{i=1}^k gain_i / log_2(i+1).\n",
    "    \"\"\"\n",
    "    dcg = 0\n",
    "    for i in range(0, min(k, len(gains))):\n",
    "        dcg += gains[i] / math.log(i + 2, 2)\n",
    "    return dcg\n",
    "\n",
    "def ndcg(gains, ideal_gains, k=5):\n",
    "    \"\"\"Computes NDCG given gains for a ranking as well as the ideal gains.\"\"\"\n",
    "    try:\n",
    "        return dcg(gains, k) / dcg(ideal_gains, k)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def get_type_path(type, type_hierarchy):\n",
    "    \"\"\"\n",
    "    Gets the type's path in the hierarchy (excluding the root type, like owl:Thing).\n",
    "    The path for each type is computed only once then cached in type_hierarchy,\n",
    "    to save computation.\n",
    "    \"\"\"\n",
    "    if not type in type_hierarchy:\n",
    "        type_hierarchy[type] = {'depth':1, 'parent':'', 'path':[type]}\n",
    "    return type_hierarchy[type]['path']\n",
    "\n",
    "def get_type_distance(type1, type2, type_hierarchy):\n",
    "    \"\"\"\n",
    "    Computes the distance between two types in the hierarchy.\n",
    "    Distance is defined to be the number of steps between them in the hierarchy,\n",
    "    if they lie on the same path (which is 0 if the two types match), and\n",
    "    infinity otherwise.\n",
    "    \"\"\"\n",
    "    type1_path = get_type_path(type1, type_hierarchy)\n",
    "    type2_path = get_type_path(type2, type_hierarchy)\n",
    "    distance = math.inf\n",
    "    if type1 in type2_path:\n",
    "        distance = type2_path.index(type1)\n",
    "    if type2 in type1_path:\n",
    "        distance = min(type1_path.index(type2), distance)\n",
    "    return distance\n",
    "\n",
    "def get_most_specific_types(types, type_hierarchy):\n",
    "    \"\"\"Filters a set of input types to most specific types w.r.t the type\n",
    "    hierarchy; i.e., super-types are removed.\"\"\"\n",
    "    filtered_types = set(types)\n",
    "    for type in types:\n",
    "        type_path = get_type_path(type, type_hierarchy)\n",
    "        for supertype in type_path[1:]:\n",
    "            if supertype in filtered_types:\n",
    "                filtered_types.remove(supertype)\n",
    "    return filtered_types\n",
    "\n",
    "def get_expanded_types(types, type_hierarchy):\n",
    "    \"\"\"Expands a set of types with both more specific and more generic types\n",
    "    (i.e., all super-types and sub-types).\"\"\"\n",
    "    expanded_types = set()\n",
    "    for type in types:\n",
    "        # Adding all supertypes.\n",
    "        expanded_types.update(get_type_path(type, type_hierarchy))\n",
    "        # Adding all subtypes (NOTE: this bit could be done more efficiently).\n",
    "        for type2 in type_hierarchy:\n",
    "            if type_hierarchy[type2]['depth'] <= type_hierarchy[type]['depth']:\n",
    "                continue\n",
    "            type2_path = get_type_path(type2, type_hierarchy)\n",
    "            if type in type2_path:\n",
    "                expanded_types.update(type2_path)\n",
    "    return expanded_types\n",
    "\n",
    "def compute_type_gains(predicted_types, gold_types, type_hierarchy, max_depth):\n",
    "    \"\"\"Computes gains for a ranked list of type predictions.\n",
    "\n",
    "    Following the definition of Linear gain in (Balog and Neumayer, CIKM'12),\n",
    "    the gain for a given predicted type is 0 if it is not on the same path with\n",
    "    any of the gold types, and otherwise it's $1-d(t,t_q)/h$ where $d(t,t_q)$ is\n",
    "    the distance between the predicted type and the closest matching gold type\n",
    "    in the type hierarchy and h is the maximum depth of the type hierarchy.\n",
    "\n",
    "    Args:\n",
    "        predicted_types: Ranked list of predicted types.\n",
    "        gold_types: List/set of gold types (i.e., perfect answers).\n",
    "        type_hierarchy: Dict with type hierarchy.\n",
    "        max_depth: Maximum depth of the type hierarchy.\n",
    "\n",
    "    Returns:\n",
    "        List with gain values corresponding to each item in predicted_types.\n",
    "    \"\"\"\n",
    "    gains = []\n",
    "    expanded_gold_types = get_expanded_types(gold_types, type_hierarchy)\n",
    "    for predicted_type in predicted_types:\n",
    "        if predicted_type in expanded_gold_types:\n",
    "            # Since not all gold types may lie on the same branch, we take the\n",
    "            # closest gold type for determining distance.\n",
    "            min_distance = math.inf\n",
    "            for gold_type in gold_types:\n",
    "                min_distance = min(get_type_distance(predicted_type, gold_type,\n",
    "                                                     type_hierarchy),\n",
    "                                   min_distance)\n",
    "            gains.append(1 - min_distance / max_depth)\n",
    "        else:\n",
    "            gains.append(0)\n",
    "    return gains\n",
    "\n",
    "def evaluate(result):\n",
    "    accuracy, ndcg_5, ndcg_10 = [], [], []\n",
    "    for qId, obj in training_queries.items():\n",
    "        if qId not in result:\n",
    "            continue\n",
    "\n",
    "        qTypes = obj['type'].split(' ')\n",
    "        if len(qTypes) == 0:\n",
    "            continue\n",
    "\n",
    "        predicted_category = result[qId].get('category', None)\n",
    "        predicted_type = result[qId].get('type', [None])\n",
    "        accuracy.append(result[qId].get('match', 0))\n",
    "\n",
    "        # Filters obj types to most specific ones in the hierarchy.\n",
    "        obj_types = get_most_specific_types(qTypes, type_hierarchy)\n",
    "        gains = compute_type_gains(predicted_type, obj_types, type_hierarchy, max_depth)\n",
    "        ideal_gains = sorted(\n",
    "                compute_type_gains(\n",
    "                get_expanded_types(obj_types, type_hierarchy), obj_types,\n",
    "                type_hierarchy, max_depth), reverse=True)\n",
    "\n",
    "        ndcg_5.append(ndcg(gains, ideal_gains, k=5))\n",
    "        ndcg_10.append(ndcg(gains, ideal_gains, k=10))\n",
    "        \n",
    "    print('Evaluation results:')\n",
    "    print('-------------------')\n",
    "    print('Category prediction (based on {} questions)'.format(len(accuracy)))\n",
    "    print('  Accuracy: {:5.3f}'.format(sum(accuracy) / len(accuracy)))\n",
    "    print('Type ranking (based on {} questions)'.format(len(ndcg_5)))\n",
    "    print('  NDCG@5:  {:5.3f}'.format(sum(ndcg_5) / len(ndcg_5)))\n",
    "    print('  NDCG@10: {:5.3f}'.format(sum(ndcg_10) / len(ndcg_10)))\n",
    "\n",
    "def write_result_to_file(res, file):\n",
    "    with open('./results/{}.csv'.format(file), 'w') as f:\n",
    "        for qId, obj in res.items():\n",
    "            f.write('{},{},{}\\n'.format(qId, obj['match'], ' '.join(obj['type'])))\n",
    "\n",
    "def read_result_from_file(file):\n",
    "    result = {}\n",
    "    with open('./results/{}.csv'.format(file), 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(',')\n",
    "            if len(line) != 3:\n",
    "                continue\n",
    "            result[line[0]] = {\n",
    "                'type': [v for v in line[-1].split(' ') if len(v) > 0],\n",
    "                'category': 'resource',\n",
    "                'match': int(line[1])\n",
    "            }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress - 50/9557 queries handled.\n",
      "Progress - 100/9557 queries handled.\n",
      "Progress - 150/9557 queries handled.\n",
      "Progress - 200/9557 queries handled.\n",
      "Progress - 250/9557 queries handled.\n",
      "Progress - 300/9557 queries handled.\n",
      "Progress - 350/9557 queries handled.\n",
      "Progress - 400/9557 queries handled.\n",
      "Progress - 450/9557 queries handled.\n",
      "Progress - 500/9557 queries handled.\n",
      "Progress - 550/9557 queries handled.\n",
      "Progress - 600/9557 queries handled.\n",
      "Progress - 650/9557 queries handled.\n",
      "Progress - 700/9557 queries handled.\n",
      "Progress - 750/9557 queries handled.\n",
      "Progress - 800/9557 queries handled.\n",
      "Progress - 850/9557 queries handled.\n",
      "Progress - 900/9557 queries handled.\n",
      "Progress - 950/9557 queries handled.\n",
      "Progress - 1000/9557 queries handled.\n",
      "Progress - 1050/9557 queries handled.\n",
      "Progress - 1100/9557 queries handled.\n",
      "Progress - 1150/9557 queries handled.\n",
      "Progress - 1200/9557 queries handled.\n",
      "Progress - 1250/9557 queries handled.\n",
      "Progress - 1300/9557 queries handled.\n",
      "Progress - 1350/9557 queries handled.\n",
      "Progress - 1400/9557 queries handled.\n",
      "Progress - 1450/9557 queries handled.\n",
      "Progress - 1500/9557 queries handled.\n",
      "Progress - 1550/9557 queries handled.\n",
      "Progress - 1600/9557 queries handled.\n",
      "Progress - 1650/9557 queries handled.\n",
      "Progress - 1700/9557 queries handled.\n",
      "Progress - 1750/9557 queries handled.\n",
      "Progress - 1800/9557 queries handled.\n",
      "Progress - 1850/9557 queries handled.\n",
      "Progress - 1900/9557 queries handled.\n",
      "Progress - 1950/9557 queries handled.\n",
      "Progress - 2000/9557 queries handled.\n",
      "Progress - 2050/9557 queries handled.\n",
      "Progress - 2100/9557 queries handled.\n",
      "Progress - 2150/9557 queries handled.\n",
      "Progress - 2200/9557 queries handled.\n",
      "Progress - 2250/9557 queries handled.\n",
      "Progress - 2300/9557 queries handled.\n",
      "Progress - 2350/9557 queries handled.\n",
      "Progress - 2400/9557 queries handled.\n",
      "Progress - 2450/9557 queries handled.\n",
      "Progress - 2500/9557 queries handled.\n",
      "Progress - 2550/9557 queries handled.\n",
      "Progress - 2600/9557 queries handled.\n",
      "Progress - 2650/9557 queries handled.\n",
      "Progress - 2700/9557 queries handled.\n",
      "Progress - 2750/9557 queries handled.\n",
      "Progress - 2800/9557 queries handled.\n",
      "Progress - 2850/9557 queries handled.\n",
      "Progress - 2900/9557 queries handled.\n",
      "Progress - 2950/9557 queries handled.\n",
      "Progress - 3000/9557 queries handled.\n",
      "Progress - 3050/9557 queries handled.\n",
      "Progress - 3100/9557 queries handled.\n",
      "Progress - 3150/9557 queries handled.\n",
      "Progress - 3200/9557 queries handled.\n",
      "Progress - 3250/9557 queries handled.\n",
      "Progress - 3300/9557 queries handled.\n",
      "Progress - 3350/9557 queries handled.\n",
      "Progress - 3400/9557 queries handled.\n",
      "Progress - 3450/9557 queries handled.\n",
      "Progress - 3500/9557 queries handled.\n",
      "Progress - 3550/9557 queries handled.\n",
      "Progress - 3600/9557 queries handled.\n",
      "Progress - 3650/9557 queries handled.\n",
      "Progress - 3700/9557 queries handled.\n",
      "Progress - 3750/9557 queries handled.\n",
      "Progress - 3800/9557 queries handled.\n",
      "Progress - 3850/9557 queries handled.\n",
      "Progress - 3900/9557 queries handled.\n",
      "Progress - 3950/9557 queries handled.\n",
      "Progress - 4000/9557 queries handled.\n",
      "Progress - 4050/9557 queries handled.\n",
      "Progress - 4100/9557 queries handled.\n",
      "Progress - 4150/9557 queries handled.\n",
      "Progress - 4200/9557 queries handled.\n",
      "Progress - 4250/9557 queries handled.\n",
      "Progress - 4300/9557 queries handled.\n",
      "Progress - 4350/9557 queries handled.\n",
      "Progress - 4400/9557 queries handled.\n",
      "Progress - 4450/9557 queries handled.\n",
      "Progress - 4500/9557 queries handled.\n",
      "Progress - 4550/9557 queries handled.\n",
      "Progress - 4600/9557 queries handled.\n",
      "Progress - 4650/9557 queries handled.\n",
      "Progress - 4700/9557 queries handled.\n",
      "Progress - 4750/9557 queries handled.\n",
      "Progress - 4800/9557 queries handled.\n",
      "Progress - 4850/9557 queries handled.\n",
      "Progress - 4900/9557 queries handled.\n",
      "Progress - 4950/9557 queries handled.\n",
      "Progress - 5000/9557 queries handled.\n",
      "Progress - 5050/9557 queries handled.\n",
      "Progress - 5100/9557 queries handled.\n",
      "Progress - 5150/9557 queries handled.\n",
      "Progress - 5200/9557 queries handled.\n",
      "Progress - 5250/9557 queries handled.\n",
      "Progress - 5300/9557 queries handled.\n",
      "Progress - 5350/9557 queries handled.\n",
      "Progress - 5400/9557 queries handled.\n",
      "Progress - 5450/9557 queries handled.\n",
      "Progress - 5500/9557 queries handled.\n",
      "Progress - 5550/9557 queries handled.\n",
      "Progress - 5600/9557 queries handled.\n",
      "Progress - 5650/9557 queries handled.\n",
      "Progress - 5700/9557 queries handled.\n",
      "Progress - 5750/9557 queries handled.\n",
      "Progress - 5800/9557 queries handled.\n",
      "Progress - 5850/9557 queries handled.\n",
      "Progress - 5900/9557 queries handled.\n",
      "Progress - 5950/9557 queries handled.\n",
      "Progress - 6000/9557 queries handled.\n",
      "Progress - 6050/9557 queries handled.\n",
      "Progress - 6100/9557 queries handled.\n",
      "Progress - 6150/9557 queries handled.\n",
      "Progress - 6200/9557 queries handled.\n",
      "Progress - 6250/9557 queries handled.\n",
      "Progress - 6300/9557 queries handled.\n",
      "Progress - 6350/9557 queries handled.\n",
      "Progress - 6400/9557 queries handled.\n",
      "Progress - 6450/9557 queries handled.\n",
      "Progress - 6500/9557 queries handled.\n",
      "Progress - 6550/9557 queries handled.\n",
      "Progress - 6600/9557 queries handled.\n",
      "Progress - 6650/9557 queries handled.\n",
      "Progress - 6700/9557 queries handled.\n",
      "Progress - 6750/9557 queries handled.\n",
      "Progress - 6800/9557 queries handled.\n",
      "Progress - 6850/9557 queries handled.\n",
      "Progress - 6900/9557 queries handled.\n",
      "Progress - 6950/9557 queries handled.\n",
      "Progress - 7000/9557 queries handled.\n",
      "Progress - 7050/9557 queries handled.\n",
      "Progress - 7100/9557 queries handled.\n",
      "Progress - 7150/9557 queries handled.\n",
      "Progress - 7200/9557 queries handled.\n",
      "Progress - 7250/9557 queries handled.\n",
      "Progress - 7300/9557 queries handled.\n",
      "Progress - 7350/9557 queries handled.\n",
      "Progress - 7400/9557 queries handled.\n",
      "Progress - 7450/9557 queries handled.\n",
      "Progress - 7500/9557 queries handled.\n",
      "Progress - 7550/9557 queries handled.\n",
      "Progress - 7600/9557 queries handled.\n",
      "Progress - 7650/9557 queries handled.\n",
      "Progress - 7700/9557 queries handled.\n",
      "Progress - 7750/9557 queries handled.\n",
      "Progress - 7800/9557 queries handled.\n",
      "Progress - 7850/9557 queries handled.\n",
      "Progress - 7900/9557 queries handled.\n",
      "Progress - 7950/9557 queries handled.\n",
      "Progress - 8000/9557 queries handled.\n",
      "Progress - 8050/9557 queries handled.\n",
      "Progress - 8100/9557 queries handled.\n",
      "Progress - 8150/9557 queries handled.\n",
      "Progress - 8200/9557 queries handled.\n",
      "Progress - 8250/9557 queries handled.\n",
      "Progress - 8300/9557 queries handled.\n",
      "Progress - 8350/9557 queries handled.\n",
      "Progress - 8400/9557 queries handled.\n",
      "Progress - 8450/9557 queries handled.\n",
      "Progress - 8500/9557 queries handled.\n",
      "Progress - 8550/9557 queries handled.\n",
      "Progress - 8600/9557 queries handled.\n",
      "Progress - 8650/9557 queries handled.\n",
      "Progress - 8700/9557 queries handled.\n",
      "Progress - 8750/9557 queries handled.\n",
      "Progress - 8800/9557 queries handled.\n",
      "Progress - 8850/9557 queries handled.\n",
      "Progress - 8900/9557 queries handled.\n",
      "Progress - 8950/9557 queries handled.\n",
      "Progress - 9000/9557 queries handled.\n",
      "Progress - 9050/9557 queries handled.\n",
      "Progress - 9100/9557 queries handled.\n",
      "Progress - 9150/9557 queries handled.\n",
      "Progress - 9200/9557 queries handled.\n",
      "Progress - 9250/9557 queries handled.\n",
      "Progress - 9300/9557 queries handled.\n",
      "Progress - 9350/9557 queries handled.\n",
      "Progress - 9400/9557 queries handled.\n",
      "Progress - 9450/9557 queries handled.\n",
      "Progress - 9500/9557 queries handled.\n",
      "Progress - 9550/9557 queries handled.\n"
     ]
    }
   ],
   "source": [
    "res_baseline = evaluate_baseline(es)\n",
    "write_result_to_file(res_baseline, 'baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "-------------------\n",
      "Category prediction (based on 9557 questions)\n",
      "  Accuracy: 0.492\n",
      "Type ranking (based on 9557 questions)\n",
      "  NDCG@5:  0.317\n",
      "  NDCG@10: 0.406\n"
     ]
    }
   ],
   "source": [
    "res_baseline = read_result_from_file('baseline')\n",
    "evaluate(res_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate advanced - Word2Vec (way too slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(EMBEDDING_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress - 50/9557 queries handled.\n",
      "Progress - 100/9557 queries handled.\n",
      "Evaluation results:\n",
      "-------------------\n",
      "Category prediction (based on 100 questions)\n",
      "  Accuracy: 0.460\n",
      "Type ranking (based on 100 questions)\n",
      "  NDCG@5:  0.342\n",
      "  NDCG@10: 0.451\n"
     ]
    }
   ],
   "source": [
    "res_adv = evaluate_advanced(es, model, k=1000, amount=100)\n",
    "evaluate(res_adv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Method, Pointwise - Classifier\n",
    "Declare documents as relevant: \n",
    "* 0 - Not relevant\n",
    "* 1 - Kinda relevant\n",
    "* 2 - Totally relevant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOB_TERM_DOC_FREQ = {} # Save computations by storing term->docFrequency in a dict. Every query will run this K times so.. be clever!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(query_terms, doc_id, es, index=INDEX_NAME):\n",
    "    \"\"\"Extracts query features, document features and query-document features of a query and document pair.\n",
    "    \n",
    "        Arguments:\n",
    "            query_terms: List of analyzed query terms.\n",
    "            doc_id: Document identifier of indexed document.\n",
    "            es: Elasticsearch object instance.\n",
    "            index: Name of relevant index on the running Elasticsearch service. \n",
    "            \n",
    "        Returns:\n",
    "            List of extracted feature values in a fixed order.\n",
    "    \"\"\"\n",
    "    query = dict(Counter(query_terms))    \n",
    "    doc_term_freqs = {} # Term frequencies in the document.\n",
    "    tv = es.termvectors(index=index, id=doc_id, fields='abstract', term_statistics=False)    \n",
    "    for term, term_stat in tv['term_vectors']['abstract']['terms'].items():\n",
    "        doc_term_freqs[term] = term_stat['term_freq']\n",
    "    \n",
    "    idf = []\n",
    "    for term in query_terms:\n",
    "        if not term in GLOB_TERM_DOC_FREQ:\n",
    "            n = 0\n",
    "            hits = es.search(\n",
    "                index=index, \n",
    "                body={\"query\": {\"bool\": {\"must\": {\"match\": {\"abstract\": term}}, \"must_not\": {\"match\": {\"instance\": \"thing\"}}}}}, \n",
    "                _source=False, size=1).get('hits',{}).get('hits',{})\n",
    "            doc_id = (hits[0]['_id'] if (len(hits) > 0) else None)\n",
    "            if doc_id is not None:\n",
    "                tv = es.termvectors(index=index, id=doc_id, fields='abstract', term_statistics=True)['term_vectors']['abstract']['terms']\n",
    "                if term in tv:\n",
    "                    n = tv[term]['doc_freq']                    \n",
    "            GLOB_TERM_DOC_FREQ[term] = n\n",
    "            \n",
    "        n = GLOB_TERM_DOC_FREQ[term]\n",
    "        if n: # Must be greater than > 0\n",
    "            idf.append(math.log(NUM_DOCS/n))\n",
    "\n",
    "    terms_doc_unique = [v for k,v in doc_term_freqs.items() if k in query] # Unique to query and doc.\n",
    "    \n",
    "    return [\n",
    "        len(query_terms),\n",
    "        sum(idf),\n",
    "        max([0] + idf),\n",
    "        (sum(idf) / max(len(idf),1)),\n",
    "        sum(doc_term_freqs.values()),\n",
    "        len(terms_doc_unique),\n",
    "        sum(terms_doc_unique),\n",
    "        max([0] + terms_doc_unique),\n",
    "        (sum(terms_doc_unique) / max(len(query.keys()),1))\n",
    "    ]\n",
    "\n",
    "def evaluate_l2r(es, k=200, amount=0, index=INDEX_NAME):\n",
    "    \"\"\"\n",
    "    Train a model, generate X - feature vectors and y - relevance labels.\n",
    "    \"\"\"\n",
    "    progress, N = 0, len(training_queries)\n",
    "    X, y, instances = [], [], []\n",
    "    for qId, queryObject in training_queries.items():\n",
    "        type_relevancy = {}        \n",
    "        for typ in queryObject['type'].split(' '):\n",
    "            if not typ in type_hierarchy:\n",
    "                continue\n",
    "            hierarchy = buildDBPediaTypeHierarchy(type_hierarchy, typ)\n",
    "            for v in hierarchy:\n",
    "                type_relevancy[v] = 1 # Relevant, its in the same hierarchy but in a diff pos.            \n",
    "                \n",
    "        for typ in queryObject['type'].split(' '):\n",
    "            type_relevancy[typ] = 2 # This is the type we want. Give it the highest weight.\n",
    "            \n",
    "        if len(type_relevancy) == 0:\n",
    "            continue\n",
    "\n",
    "        query = queryObject['analyzed']\n",
    "        hits = es.search(index=index, _source=True, size=k, \n",
    "            body={\"query\": {\"bool\": {\"must\": {\"match\": {\"abstract\": ' '.join(query)}}, \"must_not\": {\"match\": {\"instance\": \"thing\"}}}}}\n",
    "        )['hits']['hits']\n",
    "\n",
    "        for obj in hits:\n",
    "            relevancy = 0 # Default = not relevant\n",
    "            instanceType = obj['_source']['instance']\n",
    "            if instanceType in type_relevancy:\n",
    "                relevancy = type_relevancy[instanceType]\n",
    "            elif instanceType in type_hierarchy:                \n",
    "                relevancy = buildDBPediaTypeHierarchy(type_hierarchy, instanceType)\n",
    "                relevancy = max([(1 if (t in type_relevancy) else 0) for t in relevancy] + [0])\n",
    "            y.append(relevancy)\n",
    "            X.append(extract_features(query, obj['_id'], es, index))\n",
    "            instances.append(instanceType)\n",
    "\n",
    "        progress += 1\n",
    "        if (progress % 50) == 0:\n",
    "            print('Progress - {}/{} queries handled.'.format(progress, N))\n",
    "\n",
    "        if amount and (progress >= amount):\n",
    "            break\n",
    "\n",
    "    return X, y, instances\n",
    "\n",
    "def evaluate_l2r_rerank(es, model, X, instances, k=200, amount=0, index=INDEX_NAME):\n",
    "    \"\"\"\n",
    "    Evaluate our l2r model. Re-rank predicting new relevancy score!\n",
    "    \"\"\"\n",
    "    progress, N = 0, len(training_queries)\n",
    "    results, idx = {}, 0\n",
    "    predictions = (model.predict(X[:(k*amount)]) if amount else model.predict(X))\n",
    "    \n",
    "    for qId, queryObject in training_queries.items():\n",
    "        query = queryObject['analyzed']\n",
    "        hits = es.search(index=index, _source=False, size=k, \n",
    "            body={\"query\": {\"bool\": {\"must\": {\"match\": {\"abstract\": ' '.join(query)}}, \"must_not\": {\"match\": {\"instance\": \"thing\"}}}}}\n",
    "        )['hits']['hits']\n",
    "        rerank = []\n",
    "        for _ in hits:\n",
    "            rerank.append((instances[idx], predictions[idx]))\n",
    "            idx += 1\n",
    "        rerank.sort(key=lambda x:x[-1], reverse=True) # Re-rank the initial hits based on their relevancy.\n",
    "        results[qId] = {\n",
    "            'type': [v for v,_ in rerank[:10]],\n",
    "            'category': 'resource',\n",
    "            'match': max([0] + [(1 if (t in queryObject['type']) else 0) for t,_ in rerank[:10]]) # Yes / No was there an explicit match?\n",
    "        }\n",
    "\n",
    "        progress += 1\n",
    "        if (progress % 50) == 0:\n",
    "            print('Progress - {}/{} queries handled.'.format(progress, N))\n",
    "\n",
    "        if amount and (progress >= amount):\n",
    "            break\n",
    "\n",
    "    return results\n",
    "\n",
    "def evaluate_l2r_test(es, model, k=100, amount=0, index=INDEX_NAME):\n",
    "    \"\"\"\n",
    "    Predict the types for test queries. Re-rank the k docs and pick the majority vote out of the top 10.\n",
    "    If no majority vote, use the top doc type.\n",
    "    \"\"\"\n",
    "    progress, N = 0, len(test_queries)\n",
    "    results = {}\n",
    "    for qId, queryObject in test_queries.items():\n",
    "        query = queryObject['analyzed']\n",
    "        hits = es.search(index=index, _source=True, size=k, \n",
    "            body={\"query\": {\"bool\": {\"must\": {\"match\": {\"abstract\": ' '.join(query)}}, \"must_not\": {\"match\": {\"instance\": \"thing\"}}}}}\n",
    "        )['hits']['hits']\n",
    "        feat_vecs, instances = [], []\n",
    "        for obj in hits:\n",
    "            feat_vecs.append(extract_features(query, obj['_id'], es, index))\n",
    "            instances.append(obj['_source']['instance'])\n",
    "        if len(instances) == 0: # No hits!\n",
    "            results[qId] = 'N/A'\n",
    "            continue\n",
    "        instances_rerank = [instances[idx] for idx in np.argsort(model.predict(feat_vecs))[::-1]]\n",
    "        results[qId] = Counter(instances_rerank[:10]).most_common(1)[0][0]\n",
    "\n",
    "        progress += 1\n",
    "        if (progress % 50) == 0:\n",
    "            print('Progress - {}/{} queries handled.'.format(progress, N))\n",
    "\n",
    "        if amount and (progress >= amount):\n",
    "            break\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Pointwise Method (50+ min!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress - 50/9557 queries handled.\n",
      "Progress - 100/9557 queries handled.\n",
      "Progress - 150/9557 queries handled.\n",
      "Progress - 200/9557 queries handled.\n",
      "Progress - 250/9557 queries handled.\n",
      "Progress - 300/9557 queries handled.\n",
      "Progress - 350/9557 queries handled.\n",
      "Progress - 400/9557 queries handled.\n",
      "Progress - 450/9557 queries handled.\n",
      "Progress - 500/9557 queries handled.\n",
      "Progress - 550/9557 queries handled.\n",
      "Progress - 600/9557 queries handled.\n",
      "Progress - 650/9557 queries handled.\n",
      "Progress - 700/9557 queries handled.\n",
      "Progress - 750/9557 queries handled.\n",
      "Progress - 800/9557 queries handled.\n",
      "Progress - 850/9557 queries handled.\n",
      "Progress - 900/9557 queries handled.\n",
      "Progress - 950/9557 queries handled.\n",
      "Progress - 1000/9557 queries handled.\n",
      "Progress - 1050/9557 queries handled.\n",
      "Progress - 1100/9557 queries handled.\n",
      "Progress - 1150/9557 queries handled.\n",
      "Progress - 1200/9557 queries handled.\n",
      "Progress - 1250/9557 queries handled.\n",
      "Progress - 1300/9557 queries handled.\n",
      "Progress - 1350/9557 queries handled.\n",
      "Progress - 1400/9557 queries handled.\n",
      "Progress - 1450/9557 queries handled.\n",
      "Progress - 1500/9557 queries handled.\n",
      "Progress - 1550/9557 queries handled.\n",
      "Progress - 1600/9557 queries handled.\n",
      "Progress - 1650/9557 queries handled.\n",
      "Progress - 1700/9557 queries handled.\n",
      "Progress - 1750/9557 queries handled.\n",
      "Progress - 1800/9557 queries handled.\n",
      "Progress - 1850/9557 queries handled.\n",
      "Progress - 1900/9557 queries handled.\n",
      "Progress - 1950/9557 queries handled.\n",
      "Progress - 2000/9557 queries handled.\n",
      "Progress - 2050/9557 queries handled.\n",
      "Progress - 2100/9557 queries handled.\n",
      "Progress - 2150/9557 queries handled.\n",
      "Progress - 2200/9557 queries handled.\n",
      "Progress - 2250/9557 queries handled.\n",
      "Progress - 2300/9557 queries handled.\n",
      "Progress - 2350/9557 queries handled.\n",
      "Progress - 2400/9557 queries handled.\n",
      "Progress - 2450/9557 queries handled.\n",
      "Progress - 2500/9557 queries handled.\n",
      "Progress - 2550/9557 queries handled.\n",
      "Progress - 2600/9557 queries handled.\n",
      "Progress - 2650/9557 queries handled.\n",
      "Progress - 2700/9557 queries handled.\n",
      "Progress - 2750/9557 queries handled.\n",
      "Progress - 2800/9557 queries handled.\n",
      "Progress - 2850/9557 queries handled.\n",
      "Progress - 2900/9557 queries handled.\n",
      "Progress - 2950/9557 queries handled.\n",
      "Progress - 3000/9557 queries handled.\n",
      "Progress - 3050/9557 queries handled.\n",
      "Progress - 3100/9557 queries handled.\n",
      "Progress - 3150/9557 queries handled.\n",
      "Progress - 3200/9557 queries handled.\n",
      "Progress - 3250/9557 queries handled.\n",
      "Progress - 3300/9557 queries handled.\n",
      "Progress - 3350/9557 queries handled.\n",
      "Progress - 3400/9557 queries handled.\n",
      "Progress - 3450/9557 queries handled.\n",
      "Progress - 3500/9557 queries handled.\n",
      "Progress - 3550/9557 queries handled.\n",
      "Progress - 3600/9557 queries handled.\n",
      "Progress - 3650/9557 queries handled.\n",
      "Progress - 3700/9557 queries handled.\n",
      "Progress - 3750/9557 queries handled.\n",
      "Progress - 3800/9557 queries handled.\n",
      "Progress - 3850/9557 queries handled.\n",
      "Progress - 3900/9557 queries handled.\n",
      "Progress - 3950/9557 queries handled.\n",
      "Progress - 4000/9557 queries handled.\n",
      "Progress - 4050/9557 queries handled.\n",
      "Progress - 4100/9557 queries handled.\n",
      "Progress - 4150/9557 queries handled.\n",
      "Progress - 4200/9557 queries handled.\n",
      "Progress - 4250/9557 queries handled.\n",
      "Progress - 4300/9557 queries handled.\n",
      "Progress - 4350/9557 queries handled.\n",
      "Progress - 4400/9557 queries handled.\n",
      "Progress - 4450/9557 queries handled.\n",
      "Progress - 4500/9557 queries handled.\n",
      "Progress - 4550/9557 queries handled.\n",
      "Progress - 4600/9557 queries handled.\n",
      "Progress - 4650/9557 queries handled.\n",
      "Progress - 4700/9557 queries handled.\n",
      "Progress - 4750/9557 queries handled.\n",
      "Progress - 4800/9557 queries handled.\n",
      "Progress - 4850/9557 queries handled.\n",
      "Progress - 4900/9557 queries handled.\n",
      "Progress - 4950/9557 queries handled.\n",
      "Progress - 5000/9557 queries handled.\n",
      "Progress - 5050/9557 queries handled.\n",
      "Progress - 5100/9557 queries handled.\n",
      "Progress - 5150/9557 queries handled.\n",
      "Progress - 5200/9557 queries handled.\n",
      "Progress - 5250/9557 queries handled.\n",
      "Progress - 5300/9557 queries handled.\n",
      "Progress - 5350/9557 queries handled.\n",
      "Progress - 5400/9557 queries handled.\n",
      "Progress - 5450/9557 queries handled.\n",
      "Progress - 5500/9557 queries handled.\n",
      "Progress - 5550/9557 queries handled.\n",
      "Progress - 5600/9557 queries handled.\n",
      "Progress - 5650/9557 queries handled.\n",
      "Progress - 5700/9557 queries handled.\n",
      "Progress - 5750/9557 queries handled.\n",
      "Progress - 5800/9557 queries handled.\n",
      "Progress - 5850/9557 queries handled.\n",
      "Progress - 5900/9557 queries handled.\n",
      "Progress - 5950/9557 queries handled.\n",
      "Progress - 6000/9557 queries handled.\n",
      "Progress - 6050/9557 queries handled.\n",
      "Progress - 6100/9557 queries handled.\n",
      "Progress - 6150/9557 queries handled.\n",
      "Progress - 6200/9557 queries handled.\n",
      "Progress - 6250/9557 queries handled.\n",
      "Progress - 6300/9557 queries handled.\n",
      "Progress - 6350/9557 queries handled.\n",
      "Progress - 6400/9557 queries handled.\n",
      "Progress - 6450/9557 queries handled.\n",
      "Progress - 6500/9557 queries handled.\n",
      "Progress - 6550/9557 queries handled.\n",
      "Progress - 6600/9557 queries handled.\n",
      "Progress - 6650/9557 queries handled.\n",
      "Progress - 6700/9557 queries handled.\n",
      "Progress - 6750/9557 queries handled.\n",
      "Progress - 6800/9557 queries handled.\n",
      "Progress - 6850/9557 queries handled.\n",
      "Progress - 6900/9557 queries handled.\n",
      "Progress - 6950/9557 queries handled.\n",
      "Progress - 7000/9557 queries handled.\n",
      "Progress - 7050/9557 queries handled.\n",
      "Progress - 7100/9557 queries handled.\n",
      "Progress - 7150/9557 queries handled.\n",
      "Progress - 7200/9557 queries handled.\n",
      "Progress - 7250/9557 queries handled.\n",
      "Progress - 7300/9557 queries handled.\n",
      "Progress - 7350/9557 queries handled.\n",
      "Progress - 7400/9557 queries handled.\n",
      "Progress - 7450/9557 queries handled.\n",
      "Progress - 7500/9557 queries handled.\n",
      "Progress - 7550/9557 queries handled.\n",
      "Progress - 7600/9557 queries handled.\n",
      "Progress - 7650/9557 queries handled.\n",
      "Progress - 7700/9557 queries handled.\n",
      "Progress - 7750/9557 queries handled.\n",
      "Progress - 7800/9557 queries handled.\n",
      "Progress - 7850/9557 queries handled.\n",
      "Progress - 7900/9557 queries handled.\n",
      "Progress - 7950/9557 queries handled.\n",
      "Progress - 8000/9557 queries handled.\n",
      "Progress - 8050/9557 queries handled.\n",
      "Progress - 8100/9557 queries handled.\n",
      "Progress - 8150/9557 queries handled.\n",
      "Progress - 8200/9557 queries handled.\n",
      "Progress - 8250/9557 queries handled.\n",
      "Progress - 8300/9557 queries handled.\n",
      "Progress - 8350/9557 queries handled.\n",
      "Progress - 8400/9557 queries handled.\n",
      "Progress - 8450/9557 queries handled.\n",
      "Progress - 8500/9557 queries handled.\n",
      "Progress - 8550/9557 queries handled.\n",
      "Progress - 8600/9557 queries handled.\n",
      "Progress - 8650/9557 queries handled.\n",
      "Progress - 8700/9557 queries handled.\n",
      "Progress - 8750/9557 queries handled.\n",
      "Progress - 8800/9557 queries handled.\n",
      "Progress - 8850/9557 queries handled.\n",
      "Progress - 8900/9557 queries handled.\n",
      "Progress - 8950/9557 queries handled.\n",
      "Progress - 9000/9557 queries handled.\n",
      "Progress - 9050/9557 queries handled.\n",
      "Progress - 9100/9557 queries handled.\n",
      "Progress - 9150/9557 queries handled.\n",
      "Progress - 9200/9557 queries handled.\n",
      "Progress - 9250/9557 queries handled.\n",
      "Progress - 9300/9557 queries handled.\n",
      "Progress - 9350/9557 queries handled.\n",
      "Progress - 9400/9557 queries handled.\n",
      "Progress - 9450/9557 queries handled.\n",
      "Progress - 9500/9557 queries handled.\n",
      "Progress - 9550/9557 queries handled.\n",
      "Time Elapsed: 2325.64301943779\n",
      "Progress - 50/9557 queries handled.\n",
      "Progress - 100/9557 queries handled.\n",
      "Progress - 150/9557 queries handled.\n",
      "Progress - 200/9557 queries handled.\n",
      "Progress - 250/9557 queries handled.\n",
      "Progress - 300/9557 queries handled.\n",
      "Progress - 350/9557 queries handled.\n",
      "Progress - 400/9557 queries handled.\n",
      "Progress - 450/9557 queries handled.\n",
      "Progress - 500/9557 queries handled.\n",
      "Progress - 550/9557 queries handled.\n",
      "Progress - 600/9557 queries handled.\n",
      "Progress - 650/9557 queries handled.\n",
      "Progress - 700/9557 queries handled.\n",
      "Progress - 750/9557 queries handled.\n",
      "Progress - 800/9557 queries handled.\n",
      "Progress - 850/9557 queries handled.\n",
      "Progress - 900/9557 queries handled.\n",
      "Progress - 950/9557 queries handled.\n",
      "Progress - 1000/9557 queries handled.\n",
      "Progress - 1050/9557 queries handled.\n",
      "Progress - 1100/9557 queries handled.\n",
      "Progress - 1150/9557 queries handled.\n",
      "Progress - 1200/9557 queries handled.\n",
      "Progress - 1250/9557 queries handled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress - 1300/9557 queries handled.\n",
      "Progress - 1350/9557 queries handled.\n",
      "Progress - 1400/9557 queries handled.\n",
      "Progress - 1450/9557 queries handled.\n",
      "Progress - 1500/9557 queries handled.\n",
      "Progress - 1550/9557 queries handled.\n",
      "Progress - 1600/9557 queries handled.\n",
      "Progress - 1650/9557 queries handled.\n",
      "Progress - 1700/9557 queries handled.\n",
      "Progress - 1750/9557 queries handled.\n",
      "Progress - 1800/9557 queries handled.\n",
      "Progress - 1850/9557 queries handled.\n",
      "Progress - 1900/9557 queries handled.\n",
      "Progress - 1950/9557 queries handled.\n",
      "Progress - 2000/9557 queries handled.\n",
      "Progress - 2050/9557 queries handled.\n",
      "Progress - 2100/9557 queries handled.\n",
      "Progress - 2150/9557 queries handled.\n",
      "Progress - 2200/9557 queries handled.\n",
      "Progress - 2250/9557 queries handled.\n",
      "Progress - 2300/9557 queries handled.\n",
      "Progress - 2350/9557 queries handled.\n",
      "Progress - 2400/9557 queries handled.\n",
      "Progress - 2450/9557 queries handled.\n",
      "Progress - 2500/9557 queries handled.\n",
      "Progress - 2550/9557 queries handled.\n",
      "Progress - 2600/9557 queries handled.\n",
      "Progress - 2650/9557 queries handled.\n",
      "Progress - 2700/9557 queries handled.\n",
      "Progress - 2750/9557 queries handled.\n",
      "Progress - 2800/9557 queries handled.\n",
      "Progress - 2850/9557 queries handled.\n",
      "Progress - 2900/9557 queries handled.\n",
      "Progress - 2950/9557 queries handled.\n",
      "Progress - 3000/9557 queries handled.\n",
      "Progress - 3050/9557 queries handled.\n",
      "Progress - 3100/9557 queries handled.\n",
      "Progress - 3150/9557 queries handled.\n",
      "Progress - 3200/9557 queries handled.\n",
      "Progress - 3250/9557 queries handled.\n",
      "Progress - 3300/9557 queries handled.\n",
      "Progress - 3350/9557 queries handled.\n",
      "Progress - 3400/9557 queries handled.\n",
      "Progress - 3450/9557 queries handled.\n",
      "Progress - 3500/9557 queries handled.\n",
      "Progress - 3550/9557 queries handled.\n",
      "Progress - 3600/9557 queries handled.\n",
      "Progress - 3650/9557 queries handled.\n",
      "Progress - 3700/9557 queries handled.\n",
      "Progress - 3750/9557 queries handled.\n",
      "Progress - 3800/9557 queries handled.\n",
      "Progress - 3850/9557 queries handled.\n",
      "Progress - 3900/9557 queries handled.\n",
      "Progress - 3950/9557 queries handled.\n",
      "Progress - 4000/9557 queries handled.\n",
      "Progress - 4050/9557 queries handled.\n",
      "Progress - 4100/9557 queries handled.\n",
      "Progress - 4150/9557 queries handled.\n",
      "Progress - 4200/9557 queries handled.\n",
      "Progress - 4250/9557 queries handled.\n",
      "Progress - 4300/9557 queries handled.\n",
      "Progress - 4350/9557 queries handled.\n",
      "Progress - 4400/9557 queries handled.\n",
      "Progress - 4450/9557 queries handled.\n",
      "Progress - 4500/9557 queries handled.\n",
      "Progress - 4550/9557 queries handled.\n",
      "Progress - 4600/9557 queries handled.\n",
      "Progress - 4650/9557 queries handled.\n",
      "Progress - 4700/9557 queries handled.\n",
      "Progress - 4750/9557 queries handled.\n",
      "Progress - 4800/9557 queries handled.\n",
      "Progress - 4850/9557 queries handled.\n",
      "Progress - 4900/9557 queries handled.\n",
      "Progress - 4950/9557 queries handled.\n",
      "Progress - 5000/9557 queries handled.\n",
      "Progress - 5050/9557 queries handled.\n",
      "Progress - 5100/9557 queries handled.\n",
      "Progress - 5150/9557 queries handled.\n",
      "Progress - 5200/9557 queries handled.\n",
      "Progress - 5250/9557 queries handled.\n",
      "Progress - 5300/9557 queries handled.\n",
      "Progress - 5350/9557 queries handled.\n",
      "Progress - 5400/9557 queries handled.\n",
      "Progress - 5450/9557 queries handled.\n",
      "Progress - 5500/9557 queries handled.\n",
      "Progress - 5550/9557 queries handled.\n",
      "Progress - 5600/9557 queries handled.\n",
      "Progress - 5650/9557 queries handled.\n",
      "Progress - 5700/9557 queries handled.\n",
      "Progress - 5750/9557 queries handled.\n",
      "Progress - 5800/9557 queries handled.\n",
      "Progress - 5850/9557 queries handled.\n",
      "Progress - 5900/9557 queries handled.\n",
      "Progress - 5950/9557 queries handled.\n",
      "Progress - 6000/9557 queries handled.\n",
      "Progress - 6050/9557 queries handled.\n",
      "Progress - 6100/9557 queries handled.\n",
      "Progress - 6150/9557 queries handled.\n",
      "Progress - 6200/9557 queries handled.\n",
      "Progress - 6250/9557 queries handled.\n",
      "Progress - 6300/9557 queries handled.\n",
      "Progress - 6350/9557 queries handled.\n",
      "Progress - 6400/9557 queries handled.\n",
      "Progress - 6450/9557 queries handled.\n",
      "Progress - 6500/9557 queries handled.\n",
      "Progress - 6550/9557 queries handled.\n",
      "Progress - 6600/9557 queries handled.\n",
      "Progress - 6650/9557 queries handled.\n",
      "Progress - 6700/9557 queries handled.\n",
      "Progress - 6750/9557 queries handled.\n",
      "Progress - 6800/9557 queries handled.\n",
      "Progress - 6850/9557 queries handled.\n",
      "Progress - 6900/9557 queries handled.\n",
      "Progress - 6950/9557 queries handled.\n",
      "Progress - 7000/9557 queries handled.\n",
      "Progress - 7050/9557 queries handled.\n",
      "Progress - 7100/9557 queries handled.\n",
      "Progress - 7150/9557 queries handled.\n",
      "Progress - 7200/9557 queries handled.\n",
      "Progress - 7250/9557 queries handled.\n",
      "Progress - 7300/9557 queries handled.\n",
      "Progress - 7350/9557 queries handled.\n",
      "Progress - 7400/9557 queries handled.\n",
      "Progress - 7450/9557 queries handled.\n",
      "Progress - 7500/9557 queries handled.\n",
      "Progress - 7550/9557 queries handled.\n",
      "Progress - 7600/9557 queries handled.\n",
      "Progress - 7650/9557 queries handled.\n",
      "Progress - 7700/9557 queries handled.\n",
      "Progress - 7750/9557 queries handled.\n",
      "Progress - 7800/9557 queries handled.\n",
      "Progress - 7850/9557 queries handled.\n",
      "Progress - 7900/9557 queries handled.\n",
      "Progress - 7950/9557 queries handled.\n",
      "Progress - 8000/9557 queries handled.\n",
      "Progress - 8050/9557 queries handled.\n",
      "Progress - 8100/9557 queries handled.\n",
      "Progress - 8150/9557 queries handled.\n",
      "Progress - 8200/9557 queries handled.\n",
      "Progress - 8250/9557 queries handled.\n",
      "Progress - 8300/9557 queries handled.\n",
      "Progress - 8350/9557 queries handled.\n",
      "Progress - 8400/9557 queries handled.\n",
      "Progress - 8450/9557 queries handled.\n",
      "Progress - 8500/9557 queries handled.\n",
      "Progress - 8550/9557 queries handled.\n",
      "Progress - 8600/9557 queries handled.\n",
      "Progress - 8650/9557 queries handled.\n",
      "Progress - 8700/9557 queries handled.\n",
      "Progress - 8750/9557 queries handled.\n",
      "Progress - 8800/9557 queries handled.\n",
      "Progress - 8850/9557 queries handled.\n",
      "Progress - 8900/9557 queries handled.\n",
      "Progress - 8950/9557 queries handled.\n",
      "Progress - 9000/9557 queries handled.\n",
      "Progress - 9050/9557 queries handled.\n",
      "Progress - 9100/9557 queries handled.\n",
      "Progress - 9150/9557 queries handled.\n",
      "Progress - 9200/9557 queries handled.\n",
      "Progress - 9250/9557 queries handled.\n",
      "Progress - 9300/9557 queries handled.\n",
      "Progress - 9350/9557 queries handled.\n",
      "Progress - 9400/9557 queries handled.\n",
      "Progress - 9450/9557 queries handled.\n",
      "Progress - 9500/9557 queries handled.\n",
      "Progress - 9550/9557 queries handled.\n",
      "Time Elapsed: 703.2562239170074\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "X, y, instances = evaluate_l2r(es)\n",
    "print(\"Time Elapsed:\", time.time()-start)\n",
    "\n",
    "l2r_model = RandomForestClassifier(n_estimators = 100)\n",
    "_ = l2r_model.fit(X, y)\n",
    "\n",
    "start = time.time()\n",
    "res_advanced_pntwse = evaluate_l2r_rerank(es, l2r_model, X, instances)\n",
    "print(\"Time Elapsed:\", time.time()-start)\n",
    "\n",
    "write_result_to_file(res_advanced_pntwse, 'advanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "-------------------\n",
      "Category prediction (based on 9557 questions)\n",
      "  Accuracy: 0.776\n",
      "Type ranking (based on 9557 questions)\n",
      "  NDCG@5:  0.878\n",
      "  NDCG@10: 1.089\n"
     ]
    }
   ],
   "source": [
    "res_advanced_pntwse = read_result_from_file('advanced')\n",
    "evaluate(res_advanced_pntwse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc, type prediction using test queries. Predict the type of a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress - 50/4369 queries handled.\n",
      "Progress - 100/4369 queries handled.\n",
      "Progress - 150/4369 queries handled.\n",
      "Progress - 200/4369 queries handled.\n",
      "Progress - 250/4369 queries handled.\n",
      "Progress - 300/4369 queries handled.\n",
      "Progress - 350/4369 queries handled.\n",
      "Progress - 400/4369 queries handled.\n",
      "Progress - 450/4369 queries handled.\n",
      "Progress - 500/4369 queries handled.\n",
      "Progress - 550/4369 queries handled.\n",
      "Progress - 600/4369 queries handled.\n",
      "Progress - 650/4369 queries handled.\n",
      "Progress - 700/4369 queries handled.\n",
      "Progress - 750/4369 queries handled.\n",
      "Progress - 800/4369 queries handled.\n",
      "Progress - 850/4369 queries handled.\n",
      "Progress - 900/4369 queries handled.\n",
      "Progress - 950/4369 queries handled.\n",
      "Progress - 1000/4369 queries handled.\n",
      "Progress - 1050/4369 queries handled.\n",
      "Progress - 1100/4369 queries handled.\n",
      "Progress - 1150/4369 queries handled.\n",
      "Progress - 1200/4369 queries handled.\n",
      "Progress - 1250/4369 queries handled.\n",
      "Progress - 1300/4369 queries handled.\n",
      "Progress - 1350/4369 queries handled.\n",
      "Progress - 1400/4369 queries handled.\n",
      "Progress - 1450/4369 queries handled.\n",
      "Progress - 1500/4369 queries handled.\n",
      "Progress - 1550/4369 queries handled.\n",
      "Progress - 1600/4369 queries handled.\n",
      "Progress - 1650/4369 queries handled.\n",
      "Progress - 1700/4369 queries handled.\n",
      "Progress - 1750/4369 queries handled.\n",
      "Progress - 1800/4369 queries handled.\n",
      "Progress - 1850/4369 queries handled.\n",
      "Progress - 1900/4369 queries handled.\n",
      "Progress - 1950/4369 queries handled.\n",
      "Progress - 2000/4369 queries handled.\n",
      "Progress - 2050/4369 queries handled.\n",
      "Progress - 2100/4369 queries handled.\n",
      "Progress - 2150/4369 queries handled.\n",
      "Progress - 2200/4369 queries handled.\n",
      "Progress - 2250/4369 queries handled.\n",
      "Progress - 2300/4369 queries handled.\n",
      "Progress - 2350/4369 queries handled.\n",
      "Progress - 2400/4369 queries handled.\n",
      "Progress - 2450/4369 queries handled.\n",
      "Progress - 2500/4369 queries handled.\n",
      "Progress - 2550/4369 queries handled.\n",
      "Progress - 2600/4369 queries handled.\n",
      "Progress - 2650/4369 queries handled.\n",
      "Progress - 2700/4369 queries handled.\n",
      "Progress - 2750/4369 queries handled.\n",
      "Progress - 2800/4369 queries handled.\n",
      "Progress - 2850/4369 queries handled.\n",
      "Progress - 2900/4369 queries handled.\n",
      "Progress - 2950/4369 queries handled.\n",
      "Progress - 3000/4369 queries handled.\n",
      "Progress - 3050/4369 queries handled.\n",
      "Progress - 3100/4369 queries handled.\n",
      "Progress - 3150/4369 queries handled.\n",
      "Progress - 3200/4369 queries handled.\n",
      "Progress - 3250/4369 queries handled.\n",
      "Progress - 3300/4369 queries handled.\n",
      "Progress - 3350/4369 queries handled.\n",
      "Progress - 3400/4369 queries handled.\n",
      "Progress - 3450/4369 queries handled.\n",
      "Progress - 3500/4369 queries handled.\n",
      "Progress - 3550/4369 queries handled.\n",
      "Progress - 3600/4369 queries handled.\n",
      "Progress - 3650/4369 queries handled.\n",
      "Progress - 3700/4369 queries handled.\n",
      "Progress - 3750/4369 queries handled.\n",
      "Progress - 3800/4369 queries handled.\n",
      "Progress - 3850/4369 queries handled.\n",
      "Progress - 3900/4369 queries handled.\n",
      "Progress - 3950/4369 queries handled.\n",
      "Progress - 4000/4369 queries handled.\n",
      "Progress - 4050/4369 queries handled.\n",
      "Progress - 4100/4369 queries handled.\n",
      "Progress - 4150/4369 queries handled.\n",
      "Progress - 4200/4369 queries handled.\n",
      "Progress - 4250/4369 queries handled.\n",
      "Progress - 4300/4369 queries handled.\n",
      "Progress - 4350/4369 queries handled.\n"
     ]
    }
   ],
   "source": [
    "test_type_res = evaluate_l2r_test(es, l2r_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_test_types(res, file):\n",
    "    with open('./results/{}.csv'.format(file), 'w') as f:\n",
    "        for qId, obj in res.items():\n",
    "            f.write('{},{}\\n'.format(qId, obj))\n",
    "            \n",
    "def read_test_types(file):\n",
    "    result = {}\n",
    "    with open('./results/{}.csv'.format(file), 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(',')\n",
    "            if len(line) != 2:\n",
    "                continue\n",
    "            result[line[0]] = line[1]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_test_types(test_type_res, 'test_type_predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: how many platforms does tomb raider have \n",
      "Type: videogame\n"
     ]
    }
   ],
   "source": [
    "test_type_res = read_test_types('test_type_predictions')\n",
    "print('Query:', test_queries['dbpedia_687']['query'], '\\nType:', test_type_res['dbpedia_687'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dbpedia_16015': 'company',\n",
       " 'dbpedia_3885': 'person',\n",
       " 'dbpedia_12907': 'plant',\n",
       " 'dbpedia_7955': 'film',\n",
       " 'dbpedia_2376': 'album',\n",
       " 'dbpedia_4197': 'mountain',\n",
       " 'dbpedia_22599': 'militaryperson',\n",
       " 'dbpedia_5469': 'school',\n",
       " 'dbpedia_687': 'videogame',\n",
       " 'dbpedia_19677': 'mountain',\n",
       " 'dbpedia_15673': 'film',\n",
       " 'dbpedia_11163': 'person',\n",
       " 'dbpedia_4173': 'australianrulesfootballplayer',\n",
       " 'dbpedia_18169': 'software',\n",
       " 'dbpedia_10686': 'award',\n",
       " 'dbpedia_5678': 'person',\n",
       " 'dbpedia_18792': 'organisation',\n",
       " 'dbpedia_5481': 'person',\n",
       " 'dbpedia_2013': 'protectedarea',\n",
       " 'dbpedia_11251': 'lacrosseplayer',\n",
       " 'dbpedia_17993': 'film',\n",
       " 'dbpedia_20546': 'politician',\n",
       " 'dbpedia_17589': 'single',\n",
       " 'dbpedia_10307': 'company',\n",
       " 'dbpedia_865': 'band',\n",
       " 'dbpedia_15502': 'planet',\n",
       " 'dbpedia_2096': 'person',\n",
       " 'dbpedia_15898': 'programminglanguage',\n",
       " 'dbpedia_11557': 'insect',\n",
       " 'dbpedia_18447': 'person',\n",
       " 'dbpedia_20324': 'book',\n",
       " 'dbpedia_21857': 'river',\n",
       " 'dbpedia_20790': 'person',\n",
       " 'dbpedia_17145': 'election',\n",
       " 'dbpedia_20450': 'radiostation',\n",
       " 'dbpedia_18827': 'company',\n",
       " 'dbpedia_20582': 'sportsteammember',\n",
       " 'dbpedia_6724': 'film',\n",
       " 'dbpedia_17542': 'scientist',\n",
       " 'dbpedia_12072': 'film',\n",
       " 'dbpedia_7166': 'soccerclub',\n",
       " 'dbpedia_15701': 'school',\n",
       " 'dbpedia_16236': 'artwork',\n",
       " 'dbpedia_2904': 'academicjournal',\n",
       " 'dbpedia_6065': 'school',\n",
       " 'dbpedia_13035': 'governmentagency',\n",
       " 'dbpedia_3743': 'single',\n",
       " 'dbpedia_11441': 'single',\n",
       " 'dbpedia_21275': 'company',\n",
       " 'dbpedia_2169': 'film',\n",
       " 'dbpedia_8309': 'chemicalcompound',\n",
       " 'dbpedia_14696': 'politicalparty',\n",
       " 'dbpedia_6686': 'musicalartist',\n",
       " 'dbpedia_8477': 'hollywoodcartoon',\n",
       " 'dbpedia_20621': 'dam',\n",
       " 'dbpedia_13081': 'painter',\n",
       " 'dbpedia_11342': 'writer',\n",
       " 'dbpedia_1610': 'election',\n",
       " 'dbpedia_5531': 'album',\n",
       " 'dbpedia_22145': 'powerstation',\n",
       " 'dbpedia_5991': 'disease',\n",
       " 'dbpedia_20965': 'comicscharacter',\n",
       " 'dbpedia_9328': 'musicalartist',\n",
       " 'dbpedia_17196': 'album',\n",
       " 'dbpedia_17597': 'village',\n",
       " 'dbpedia_8151': 'settlement',\n",
       " 'dbpedia_1645': 'company',\n",
       " 'dbpedia_21999': 'fish',\n",
       " 'dbpedia_22136': 'mountain',\n",
       " 'dbpedia_12376': 'single',\n",
       " 'dbpedia_21435': 'soccermanager',\n",
       " 'dbpedia_18496': 'album',\n",
       " 'dbpedia_19727': 'person',\n",
       " 'dbpedia_20944': 'baseballplayer',\n",
       " 'dbpedia_20180': 'book',\n",
       " 'dbpedia_8843': 'person',\n",
       " 'dbpedia_1051': 'comic',\n",
       " 'dbpedia_6930': 'fictionalcharacter',\n",
       " 'dbpedia_16217': 'lake',\n",
       " 'dbpedia_9441': 'radiostation',\n",
       " 'dbpedia_10394': 'organisation',\n",
       " 'dbpedia_20499': 'company',\n",
       " 'dbpedia_15198': 'organisation',\n",
       " 'dbpedia_1201': 'officeholder',\n",
       " 'dbpedia_539': 'royalty',\n",
       " 'dbpedia_18580': 'fictionalcharacter',\n",
       " 'dbpedia_11754': 'book',\n",
       " 'dbpedia_12509': 'company',\n",
       " 'dbpedia_3527': 'building',\n",
       " 'dbpedia_15115': 'ncaateamseason',\n",
       " 'dbpedia_4528': 'album',\n",
       " 'dbpedia_6357': 'film',\n",
       " 'dbpedia_22921': 'film',\n",
       " 'dbpedia_12974': 'river',\n",
       " 'dbpedia_15288': 'chemicalcompound',\n",
       " 'dbpedia_11098': 'album',\n",
       " 'dbpedia_9367': 'ship',\n",
       " 'dbpedia_18939': 'athlete',\n",
       " 'dbpedia_15841': 'book',\n",
       " 'dbpedia_1824': 'album',\n",
       " 'dbpedia_13440': 'person',\n",
       " 'dbpedia_16430': 'nascardriver',\n",
       " 'dbpedia_848': 'film',\n",
       " 'dbpedia_23201': 'disease',\n",
       " 'dbpedia_3865': 'settlement',\n",
       " 'dbpedia_6892': 'royalty',\n",
       " 'dbpedia_3331': 'country',\n",
       " 'dbpedia_702': 'soccerplayer',\n",
       " 'dbpedia_10585': 'chessplayer',\n",
       " 'dbpedia_8002': 'organisation',\n",
       " 'dbpedia_18653': 'televisionshow',\n",
       " 'dbpedia_22392': 'airline',\n",
       " 'dbpedia_20972': 'town',\n",
       " 'dbpedia_13276': 'drug',\n",
       " 'dbpedia_4897': 'film',\n",
       " 'dbpedia_12655': 'album',\n",
       " 'dbpedia_21184': 'single',\n",
       " 'dbpedia_5424': 'village',\n",
       " 'dbpedia_12705': 'film',\n",
       " 'dbpedia_3240': 'chemicalcompound',\n",
       " 'dbpedia_5736': 'planet',\n",
       " 'dbpedia_183': 'country',\n",
       " 'dbpedia_19905': 'mountainrange',\n",
       " 'dbpedia_671': 'film',\n",
       " 'dbpedia_4461': 'school',\n",
       " 'dbpedia_22987': 'person',\n",
       " 'dbpedia_5924': 'judge',\n",
       " 'dbpedia_19549': 'soccermanager',\n",
       " 'dbpedia_8646': 'disease',\n",
       " 'dbpedia_1673': 'scientist',\n",
       " 'dbpedia_18238': 'televisionshow',\n",
       " 'dbpedia_3263': 'person',\n",
       " 'dbpedia_14411': 'building',\n",
       " 'dbpedia_3994': 'film',\n",
       " 'dbpedia_8652': 'film',\n",
       " 'dbpedia_17': 'musicalartist',\n",
       " 'dbpedia_15760': 'person',\n",
       " 'dbpedia_9621': 'chemicalcompound',\n",
       " 'dbpedia_1803': 'award',\n",
       " 'dbpedia_3066': 'language',\n",
       " 'dbpedia_10108': 'person',\n",
       " 'dbpedia_11951': 'building',\n",
       " 'dbpedia_6872': 'chemicalcompound',\n",
       " 'dbpedia_1118': 'officeholder',\n",
       " 'dbpedia_3529': 'film',\n",
       " 'dbpedia_14136': 'planet',\n",
       " 'dbpedia_12827': 'person',\n",
       " 'dbpedia_2452': 'software',\n",
       " 'dbpedia_19213': 'politicalparty',\n",
       " 'dbpedia_13563': 'cheese',\n",
       " 'dbpedia_23102': 'company',\n",
       " 'dbpedia_20082': 'film',\n",
       " 'dbpedia_13561': 'lake',\n",
       " 'dbpedia_13491': 'cyclist',\n",
       " 'dbpedia_15307': 'protein',\n",
       " 'dbpedia_19674': 'settlement',\n",
       " 'dbpedia_10691': 'N/A',\n",
       " 'dbpedia_6007': 'airport',\n",
       " 'dbpedia_3815': 'book',\n",
       " 'dbpedia_17450': 'company',\n",
       " 'dbpedia_17575': 'award',\n",
       " 'dbpedia_20628': 'historicplace',\n",
       " 'dbpedia_19633': 'musicalartist',\n",
       " 'dbpedia_4317': 'scientist',\n",
       " 'dbpedia_14301': 'soccerplayer',\n",
       " 'dbpedia_21450': 'televisionepisode',\n",
       " 'dbpedia_988': 'film',\n",
       " 'dbpedia_18265': 'book',\n",
       " 'dbpedia_15086': 'person',\n",
       " 'dbpedia_15202': 'film',\n",
       " 'dbpedia_9494': 'river',\n",
       " 'dbpedia_13088': 'insect',\n",
       " 'dbpedia_11873': 'film',\n",
       " 'dbpedia_13022': 'person',\n",
       " 'dbpedia_7186': 'militaryconflict',\n",
       " 'dbpedia_15955': 'televisionshow',\n",
       " 'dbpedia_9296': 'settlement',\n",
       " 'dbpedia_14762': 'officeholder',\n",
       " 'dbpedia_9778': 'person',\n",
       " 'dbpedia_7787': 'tennisplayer',\n",
       " 'dbpedia_9131': 'artificialsatellite',\n",
       " 'dbpedia_624': 'film',\n",
       " 'dbpedia_22104': 'soccerplayer',\n",
       " 'dbpedia_11371': 'election',\n",
       " 'dbpedia_7295': 'company',\n",
       " 'dbpedia_8130': 'film',\n",
       " 'dbpedia_15008': 'settlement',\n",
       " 'dbpedia_350': 'book',\n",
       " 'dbpedia_5033': 'book',\n",
       " 'dbpedia_17579': 'settlement',\n",
       " 'dbpedia_15736': 'militaryperson',\n",
       " 'dbpedia_17832': 'saint',\n",
       " 'dbpedia_14101': 'road',\n",
       " 'dbpedia_20589': 'film',\n",
       " 'dbpedia_14563': 'fictionalcharacter',\n",
       " 'dbpedia_5915': 'videogame',\n",
       " 'dbpedia_10964': 'academicjournal',\n",
       " 'dbpedia_20263': 'film',\n",
       " 'dbpedia_10652': 'film',\n",
       " 'dbpedia_17518': 'militaryconflict',\n",
       " 'dbpedia_20480': 'person',\n",
       " 'dbpedia_19380': 'person',\n",
       " 'dbpedia_388': 'criminal',\n",
       " 'dbpedia_3143': 'island',\n",
       " 'dbpedia_7269': 'enzyme',\n",
       " 'dbpedia_10866': 'person',\n",
       " 'dbpedia_17932': 'park',\n",
       " 'dbpedia_3078': 'locomotive',\n",
       " 'dbpedia_11988': 'aircraft',\n",
       " 'dbpedia_22595': 'software',\n",
       " 'dbpedia_12448': 'ncaateamseason',\n",
       " 'dbpedia_2745': 'televisionshow',\n",
       " 'dbpedia_5561': 'album',\n",
       " 'dbpedia_19930': 'road',\n",
       " 'dbpedia_16931': 'astronaut',\n",
       " 'dbpedia_4989': 'soccerclub',\n",
       " 'dbpedia_21566': 'televisionshow',\n",
       " 'dbpedia_9117': 'company',\n",
       " 'dbpedia_12865': 'album',\n",
       " 'dbpedia_18553': 'academicjournal',\n",
       " 'dbpedia_11474': 'album',\n",
       " 'dbpedia_6558': 'historicbuilding',\n",
       " 'dbpedia_22533': 'ncaateamseason',\n",
       " 'dbpedia_20440': 'lake',\n",
       " 'dbpedia_6847': 'road',\n",
       " 'dbpedia_22037': 'newspaper',\n",
       " 'dbpedia_10471': 'single',\n",
       " 'dbpedia_4801': 'settlement',\n",
       " 'dbpedia_15084': 'writer',\n",
       " 'dbpedia_4760': 'academicjournal',\n",
       " 'dbpedia_3519': 'software',\n",
       " 'dbpedia_18430': 'fish',\n",
       " 'dbpedia_6993': 'album',\n",
       " 'dbpedia_14516': 'software',\n",
       " 'dbpedia_8054': 'mollusca',\n",
       " 'dbpedia_19117': 'organisation',\n",
       " 'dbpedia_22787': 'organisation',\n",
       " 'dbpedia_20306': 'americanfootballplayer',\n",
       " 'dbpedia_12859': 'film',\n",
       " 'dbpedia_8122': 'legislature',\n",
       " 'dbpedia_2457': 'building',\n",
       " 'dbpedia_14045': 'person',\n",
       " 'dbpedia_18296': 'single',\n",
       " 'dbpedia_14542': 'scientist',\n",
       " 'dbpedia_290': 'album',\n",
       " 'dbpedia_12959': 'videogame',\n",
       " 'dbpedia_10661': 'lake',\n",
       " 'dbpedia_20065': 'videogame',\n",
       " 'dbpedia_14915': 'album',\n",
       " 'dbpedia_20776': 'administrativeregion',\n",
       " 'dbpedia_19704': 'organisation',\n",
       " 'dbpedia_14328': 'single',\n",
       " 'dbpedia_8615': 'writer',\n",
       " 'dbpedia_1999': 'aircraft',\n",
       " 'dbpedia_19364': 'writer',\n",
       " 'dbpedia_8664': 'plant',\n",
       " 'dbpedia_22194': 'currency',\n",
       " 'dbpedia_23548': 'single',\n",
       " 'dbpedia_22137': 'scientist',\n",
       " 'dbpedia_20711': 'televisionshow',\n",
       " 'dbpedia_10716': 'person',\n",
       " 'dbpedia_13812': 'cricketer',\n",
       " 'dbpedia_12820': 'philosopher',\n",
       " 'dbpedia_16155': 'philosopher',\n",
       " 'dbpedia_5338': 'company',\n",
       " 'dbpedia_22226': 'river',\n",
       " 'dbpedia_13550': 'historicbuilding',\n",
       " 'dbpedia_13472': 'organisation',\n",
       " 'dbpedia_2934': 'film',\n",
       " 'dbpedia_10192': 'militaryunit',\n",
       " 'dbpedia_23390': 'disease',\n",
       " 'dbpedia_21821': 'company',\n",
       " 'dbpedia_2799': 'settlement',\n",
       " 'dbpedia_18065': 'chessplayer',\n",
       " 'dbpedia_7669': 'bird',\n",
       " 'dbpedia_13896': 'militaryconflict',\n",
       " 'dbpedia_8402': 'museum',\n",
       " 'dbpedia_23074': 'river',\n",
       " 'dbpedia_3035': 'videogame',\n",
       " 'dbpedia_13370': 'film',\n",
       " 'dbpedia_6434': 'station',\n",
       " 'dbpedia_2700': 'settlement',\n",
       " 'dbpedia_21118': 'gridironfootballplayer',\n",
       " 'dbpedia_16267': 'givenname',\n",
       " 'dbpedia_14152': 'scientist',\n",
       " 'dbpedia_14239': 'company',\n",
       " 'dbpedia_5897': 'athlete',\n",
       " 'dbpedia_11496': 'film',\n",
       " 'dbpedia_1553': 'company',\n",
       " 'dbpedia_21952': 'person',\n",
       " 'dbpedia_22498': 'televisionepisode',\n",
       " 'dbpedia_10433': 'enzyme',\n",
       " 'dbpedia_8064': 'mythologicalfigure',\n",
       " 'dbpedia_14453': 'artery',\n",
       " 'dbpedia_3644': 'crustacean',\n",
       " 'dbpedia_14436': 'book',\n",
       " 'dbpedia_13612': 'software',\n",
       " 'dbpedia_3070': 'software',\n",
       " 'dbpedia_1127': 'company',\n",
       " 'dbpedia_9186': 'film',\n",
       " 'dbpedia_1573': 'person',\n",
       " 'dbpedia_4373': 'chemicalcompound',\n",
       " 'dbpedia_13127': 'administrativeregion',\n",
       " 'dbpedia_571': 'militaryconflict',\n",
       " 'dbpedia_11653': 'rugbyplayer',\n",
       " 'dbpedia_3295': 'film',\n",
       " 'dbpedia_15030': 'protectedarea',\n",
       " 'dbpedia_10657': 'person',\n",
       " 'dbpedia_6322': 'album',\n",
       " 'dbpedia_10057': 'scientist',\n",
       " 'dbpedia_2223': 'single',\n",
       " 'dbpedia_22244': 'cultivatedvariety',\n",
       " 'dbpedia_13116': 'album',\n",
       " 'dbpedia_4619': 'organisation',\n",
       " 'dbpedia_1583': 'film',\n",
       " 'dbpedia_13926': 'mixedmartialartsevent',\n",
       " 'dbpedia_22521': 'person',\n",
       " 'dbpedia_8170': 'album',\n",
       " 'dbpedia_7538': 'soccerclub',\n",
       " 'dbpedia_10769': 'cyclist',\n",
       " 'dbpedia_1247': 'star',\n",
       " 'dbpedia_6492': 'officeholder',\n",
       " 'dbpedia_12469': 'royalty',\n",
       " 'dbpedia_14706': 'settlement',\n",
       " 'dbpedia_14072': 'person',\n",
       " 'dbpedia_9447': 'software',\n",
       " 'dbpedia_19263': 'city',\n",
       " 'dbpedia_16962': 'single',\n",
       " 'dbpedia_6413': 'videogame',\n",
       " 'dbpedia_8784': 'single',\n",
       " 'dbpedia_9826': 'star',\n",
       " 'dbpedia_2839': 'dam',\n",
       " 'dbpedia_20717': 'award',\n",
       " 'dbpedia_10119': 'person',\n",
       " 'dbpedia_22330': 'organisation',\n",
       " 'dbpedia_21540': 'televisionstation',\n",
       " 'dbpedia_8589': 'athlete',\n",
       " 'dbpedia_11565': 'playboyplaymate',\n",
       " 'dbpedia_8329': 'roadtunnel',\n",
       " 'dbpedia_12133': 'person',\n",
       " 'dbpedia_9527': 'person',\n",
       " 'dbpedia_10912': 'settlement',\n",
       " 'dbpedia_1791': 'militarystructure',\n",
       " 'dbpedia_15137': 'settlement',\n",
       " 'dbpedia_17651': 'person',\n",
       " 'dbpedia_6855': 'software',\n",
       " 'dbpedia_21691': 'athlete',\n",
       " 'dbpedia_5646': 'single',\n",
       " 'dbpedia_7829': 'dam',\n",
       " 'dbpedia_7293': 'film',\n",
       " 'dbpedia_3924': 'person',\n",
       " 'dbpedia_5602': 'artist',\n",
       " 'dbpedia_13541': 'plant',\n",
       " 'dbpedia_1384': 'australianrulesfootballplayer',\n",
       " 'dbpedia_5048': 'artist',\n",
       " 'dbpedia_2573': 'book',\n",
       " 'dbpedia_16557': 'mineral',\n",
       " 'dbpedia_17130': 'soapcharacter',\n",
       " 'dbpedia_21428': 'film',\n",
       " 'dbpedia_17179': 'person',\n",
       " 'dbpedia_23188': 'writer',\n",
       " 'dbpedia_18739': 'person',\n",
       " 'dbpedia_3632': 'album',\n",
       " 'dbpedia_6540': 'officeholder',\n",
       " 'dbpedia_4724': 'album',\n",
       " 'dbpedia_20699': 'musicalartist',\n",
       " 'dbpedia_2922': 'person',\n",
       " 'dbpedia_16998': 'mountain',\n",
       " 'dbpedia_16675': 'officeholder',\n",
       " 'dbpedia_12554': 'architect',\n",
       " 'dbpedia_14851': 'film',\n",
       " 'dbpedia_19073': 'building',\n",
       " 'dbpedia_7901': 'soccerclubseason',\n",
       " 'dbpedia_17840': 'person',\n",
       " 'dbpedia_7939': 'university',\n",
       " 'dbpedia_19210': 'videogame',\n",
       " 'dbpedia_4423': 'noble',\n",
       " 'dbpedia_3658': 'album',\n",
       " 'dbpedia_1592': 'royalty',\n",
       " 'dbpedia_8534': 'televisionshow',\n",
       " 'dbpedia_8485': 'building',\n",
       " 'dbpedia_5093': 'person',\n",
       " 'dbpedia_5509': 'river',\n",
       " 'dbpedia_19203': 'officeholder',\n",
       " 'dbpedia_6574': 'film',\n",
       " 'dbpedia_15605': 'ship',\n",
       " 'dbpedia_12393': 'film',\n",
       " 'dbpedia_4902': 'soccermanager',\n",
       " 'dbpedia_9498': 'scientist',\n",
       " 'dbpedia_137': 'musicalartist',\n",
       " 'dbpedia_2290': 'single',\n",
       " 'dbpedia_22434': 'film',\n",
       " 'dbpedia_7375': 'informationappliance',\n",
       " 'dbpedia_22630': 'scientist',\n",
       " 'dbpedia_20611': 'videogame',\n",
       " 'dbpedia_19854': 'televisionshow',\n",
       " 'dbpedia_6314': 'artist',\n",
       " 'dbpedia_3920': 'album',\n",
       " 'dbpedia_3109': 'bridge',\n",
       " 'dbpedia_2814': 'painter',\n",
       " 'dbpedia_657': 'film',\n",
       " 'dbpedia_15550': 'person',\n",
       " 'dbpedia_5827': 'academicjournal',\n",
       " 'dbpedia_16906': 'album',\n",
       " 'dbpedia_14899': 'person',\n",
       " 'dbpedia_12364': 'film',\n",
       " 'dbpedia_17211': 'star',\n",
       " 'dbpedia_1272': 'settlement',\n",
       " 'dbpedia_17271': 'building',\n",
       " 'dbpedia_11305': 'person',\n",
       " 'dbpedia_18568': 'baseballplayer',\n",
       " 'dbpedia_58': 'footballleagueseason',\n",
       " 'dbpedia_2035': 'person',\n",
       " 'dbpedia_357': 'person',\n",
       " 'dbpedia_20651': 'rugbyplayer',\n",
       " 'dbpedia_22469': 'stadium',\n",
       " 'dbpedia_15591': 'film',\n",
       " 'dbpedia_22236': 'chessplayer',\n",
       " 'dbpedia_9092': 'school',\n",
       " 'dbpedia_1219': 'academicjournal',\n",
       " 'dbpedia_8768': 'person',\n",
       " 'dbpedia_12586': 'person',\n",
       " 'dbpedia_6353': 'racehorse',\n",
       " 'dbpedia_7285': 'chemicalcompound',\n",
       " 'dbpedia_5788': 'year',\n",
       " 'dbpedia_9584': 'automobile',\n",
       " 'dbpedia_16311': 'album',\n",
       " 'dbpedia_2773': 'officeholder',\n",
       " 'dbpedia_9569': 'software',\n",
       " 'dbpedia_225': 'basketballplayer',\n",
       " 'dbpedia_9123': 'plant',\n",
       " 'dbpedia_5659': 'royalty',\n",
       " 'dbpedia_323': 'settlement',\n",
       " 'dbpedia_12663': 'writer',\n",
       " 'dbpedia_6633': 'insect',\n",
       " 'dbpedia_7398': 'televisionshow',\n",
       " 'dbpedia_23021': 'film',\n",
       " 'dbpedia_3624': 'politician',\n",
       " 'dbpedia_12174': 'athlete',\n",
       " 'dbpedia_798': 'royalty',\n",
       " 'dbpedia_6489': 'collegecoach',\n",
       " 'dbpedia_3958': 'musicalartist',\n",
       " 'dbpedia_6091': 'country',\n",
       " 'dbpedia_13203': 'militaryconflict',\n",
       " 'dbpedia_22311': 'televisionshow',\n",
       " 'dbpedia_17025': 'person',\n",
       " 'dbpedia_20763': 'soccerplayer',\n",
       " 'dbpedia_5770': 'single',\n",
       " 'dbpedia_7453': 'election',\n",
       " 'dbpedia_10781': 'person',\n",
       " 'dbpedia_5362': 'film',\n",
       " 'dbpedia_5270': 'militaryconflict',\n",
       " 'dbpedia_6880': 'videogame',\n",
       " 'dbpedia_3039': 'chemicalcompound',\n",
       " 'dbpedia_17658': 'protectedarea',\n",
       " 'dbpedia_12170': 'film',\n",
       " 'dbpedia_13540': 'film',\n",
       " 'dbpedia_17772': 'person',\n",
       " 'dbpedia_16786': 'school',\n",
       " 'dbpedia_12874': 'grandprix',\n",
       " 'dbpedia_20313': 'televisionstation',\n",
       " 'dbpedia_13857': 'species',\n",
       " 'dbpedia_15711': 'person',\n",
       " 'dbpedia_22378': 'river',\n",
       " 'dbpedia_3155': 'food',\n",
       " 'dbpedia_8504': 'fictionalcharacter',\n",
       " 'dbpedia_3006': 'officeholder',\n",
       " 'dbpedia_4623': 'insect',\n",
       " 'dbpedia_17761': 'bridge',\n",
       " 'dbpedia_5377': 'book',\n",
       " 'dbpedia_21039': 'airline',\n",
       " 'dbpedia_1435': 'lake',\n",
       " 'dbpedia_1394': 'diocese',\n",
       " 'dbpedia_1593': 'hospital',\n",
       " 'dbpedia_5123': 'settlement',\n",
       " 'dbpedia_22578': 'person',\n",
       " 'dbpedia_12534': 'software',\n",
       " 'dbpedia_17172': 'historicplace',\n",
       " 'dbpedia_9512': 'company',\n",
       " 'dbpedia_8383': 'star',\n",
       " 'dbpedia_22447': 'school',\n",
       " 'dbpedia_1193': 'road',\n",
       " 'dbpedia_14092': 'shoppingmall',\n",
       " 'dbpedia_18996': 'soccerclub',\n",
       " 'dbpedia_14581': 'single',\n",
       " 'dbpedia_1955': 'person',\n",
       " 'dbpedia_1447': 'writer',\n",
       " 'dbpedia_1345': 'person',\n",
       " 'dbpedia_2911': 'single',\n",
       " 'dbpedia_7242': 'year',\n",
       " 'dbpedia_17425': 'soccerplayer',\n",
       " 'dbpedia_18406': 'film',\n",
       " 'dbpedia_298': 'officeholder',\n",
       " 'dbpedia_11966': 'scientist',\n",
       " 'dbpedia_9173': 'building',\n",
       " 'dbpedia_12143': 'organisation',\n",
       " 'dbpedia_1137': 'company',\n",
       " 'dbpedia_2976': 'year',\n",
       " 'dbpedia_17087': 'historicbuilding',\n",
       " 'dbpedia_23423': 'person',\n",
       " 'dbpedia_3049': 'university',\n",
       " 'dbpedia_11832': 'scientist',\n",
       " 'dbpedia_13643': 'railwayline',\n",
       " 'dbpedia_19537': 'settlement',\n",
       " 'dbpedia_22538': 'school',\n",
       " 'dbpedia_11862': 'person',\n",
       " 'dbpedia_5914': 'single',\n",
       " 'dbpedia_5670': 'model',\n",
       " 'dbpedia_21165': 'food',\n",
       " 'dbpedia_16686': 'soccerplayer',\n",
       " 'dbpedia_11053': 'settlement',\n",
       " 'dbpedia_12531': 'person',\n",
       " 'dbpedia_10208': 'person',\n",
       " 'dbpedia_3247': 'officeholder',\n",
       " 'dbpedia_14196': 'school',\n",
       " 'dbpedia_4381': 'person',\n",
       " 'dbpedia_9011': 'militarystructure',\n",
       " 'dbpedia_7536': 'person',\n",
       " 'dbpedia_14753': 'album',\n",
       " 'dbpedia_13976': 'railwayline',\n",
       " 'dbpedia_22975': 'currency',\n",
       " 'dbpedia_16209': 'athlete',\n",
       " 'dbpedia_10539': 'disease',\n",
       " 'dbpedia_22567': 'videogame',\n",
       " 'dbpedia_19739': 'album',\n",
       " 'dbpedia_8119': 'cyclist',\n",
       " 'dbpedia_3183': 'baseballplayer',\n",
       " 'dbpedia_16060': 'software',\n",
       " 'dbpedia_9178': 'sumowrestler',\n",
       " 'dbpedia_11170': 'person',\n",
       " 'dbpedia_5810': 'person',\n",
       " 'dbpedia_5683': 'muscle',\n",
       " 'dbpedia_4124': 'galaxy',\n",
       " 'dbpedia_15315': 'person',\n",
       " 'dbpedia_2916': 'disease',\n",
       " 'dbpedia_9228': 'company',\n",
       " 'dbpedia_18402': 'book',\n",
       " 'dbpedia_9254': 'memberofparliament',\n",
       " 'dbpedia_7953': 'film',\n",
       " 'dbpedia_11736': 'chemicalcompound',\n",
       " 'dbpedia_3508': 'film',\n",
       " 'dbpedia_2391': 'album',\n",
       " 'dbpedia_9091': 'website',\n",
       " 'dbpedia_11497': 'person',\n",
       " 'dbpedia_5275': 'building',\n",
       " 'dbpedia_1865': 'militaryunit',\n",
       " 'dbpedia_15341': 'software',\n",
       " 'dbpedia_13615': 'soccermanager',\n",
       " 'dbpedia_9530': 'film',\n",
       " 'dbpedia_259': 'election',\n",
       " 'dbpedia_10078': 'disease',\n",
       " 'dbpedia_22880': 'album',\n",
       " 'dbpedia_14896': 'soccerplayer',\n",
       " 'dbpedia_13547': 'anatomicalstructure',\n",
       " 'dbpedia_13026': 'settlement',\n",
       " 'dbpedia_769': 'airport',\n",
       " 'dbpedia_17959': 'film',\n",
       " 'dbpedia_17992': 'beautyqueen',\n",
       " 'dbpedia_16839': 'insect',\n",
       " 'dbpedia_16566': 'university',\n",
       " 'dbpedia_9032': 'book',\n",
       " 'dbpedia_2711': 'recordlabel',\n",
       " 'dbpedia_19220': 'software',\n",
       " 'dbpedia_21652': 'artist',\n",
       " 'dbpedia_9327': 'motorcyclerider',\n",
       " 'dbpedia_9143': 'book',\n",
       " 'dbpedia_1691': 'soccerplayer',\n",
       " 'dbpedia_12503': 'scientist',\n",
       " 'dbpedia_12006': 'film',\n",
       " 'dbpedia_22725': 'automobile',\n",
       " 'dbpedia_3844': 'drug',\n",
       " 'dbpedia_1719': 'person',\n",
       " 'dbpedia_10616': 'film',\n",
       " 'dbpedia_2967': 'mountain',\n",
       " 'dbpedia_20985': 'academicjournal',\n",
       " 'dbpedia_16077': 'planet',\n",
       " 'dbpedia_14926': 'painter',\n",
       " 'dbpedia_18986': 'televisionshow',\n",
       " 'dbpedia_9993': 'president',\n",
       " 'dbpedia_16440': 'person',\n",
       " 'dbpedia_17505': 'person',\n",
       " 'dbpedia_13853': 'company',\n",
       " 'dbpedia_13796': 'album',\n",
       " 'dbpedia_19425': 'militaryunit',\n",
       " 'dbpedia_8816': 'musicalartist',\n",
       " 'dbpedia_17463': 'book',\n",
       " 'dbpedia_13015': 'settlement',\n",
       " 'dbpedia_13200': 'mineral',\n",
       " 'dbpedia_3981': 'company',\n",
       " 'dbpedia_3': 'star',\n",
       " 'dbpedia_21776': 'historicplace',\n",
       " 'dbpedia_19878': 'officeholder',\n",
       " 'dbpedia_20539': 'bridge',\n",
       " 'dbpedia_15301': 'album',\n",
       " 'dbpedia_18054': 'televisionshow',\n",
       " 'dbpedia_6939': 'film',\n",
       " 'dbpedia_23426': 'single',\n",
       " 'dbpedia_13902': 'militaryperson',\n",
       " 'dbpedia_16974': 'scientist',\n",
       " 'dbpedia_20095': 'settlement',\n",
       " 'dbpedia_295': 'person',\n",
       " 'dbpedia_16780': 'station',\n",
       " 'dbpedia_9863': 'mountain',\n",
       " 'dbpedia_5814': 'food',\n",
       " 'dbpedia_15234': 'company',\n",
       " 'dbpedia_1466': 'company',\n",
       " 'dbpedia_4855': 'organisation',\n",
       " 'dbpedia_3987': 'settlement',\n",
       " 'dbpedia_10793': 'chemicalcompound',\n",
       " 'dbpedia_11086': 'school',\n",
       " 'dbpedia_13886': 'insect',\n",
       " 'dbpedia_8681': 'single',\n",
       " 'dbpedia_1129': 'officeholder',\n",
       " 'dbpedia_21507': 'drug',\n",
       " 'dbpedia_9786': 'company',\n",
       " 'dbpedia_20895': 'software',\n",
       " 'dbpedia_23287': 'band',\n",
       " 'dbpedia_3835': 'island',\n",
       " 'dbpedia_22480': 'soccerplayer',\n",
       " 'dbpedia_16341': 'person',\n",
       " 'dbpedia_18250': 'soccerclub',\n",
       " 'dbpedia_6837': 'politician',\n",
       " 'dbpedia_23262': 'language',\n",
       " 'dbpedia_1453': 'footballleagueseason',\n",
       " 'dbpedia_15719': 'road',\n",
       " 'dbpedia_14032': 'officeholder',\n",
       " 'dbpedia_11899': 'militarystructure',\n",
       " 'dbpedia_1594': 'soccerplayer',\n",
       " 'dbpedia_15100': 'film',\n",
       " 'dbpedia_1317': 'writer',\n",
       " 'dbpedia_19083': 'ethnicgroup',\n",
       " 'dbpedia_20716': 'televisionshow',\n",
       " 'dbpedia_14754': 'soccerclub',\n",
       " 'dbpedia_18847': 'winery',\n",
       " 'dbpedia_8136': 'film',\n",
       " 'dbpedia_19129': 'organisation',\n",
       " 'dbpedia_3695': 'software',\n",
       " 'dbpedia_88': 'soccermanager',\n",
       " 'dbpedia_14701': 'officeholder',\n",
       " 'dbpedia_18253': 'militaryconflict',\n",
       " 'dbpedia_20530': 'militaryunit',\n",
       " 'dbpedia_17605': 'scientist',\n",
       " 'dbpedia_3645': 'person',\n",
       " 'dbpedia_23069': 'single',\n",
       " 'dbpedia_2743': 'star',\n",
       " 'dbpedia_11382': 'person',\n",
       " 'dbpedia_19493': 'person',\n",
       " 'dbpedia_17206': 'person',\n",
       " 'dbpedia_21798': 'person',\n",
       " 'dbpedia_13755': 'year',\n",
       " 'dbpedia_6343': 'settlement',\n",
       " 'dbpedia_2038': 'writtenwork',\n",
       " 'dbpedia_21076': 'company',\n",
       " 'dbpedia_4222': 'administrativeregion',\n",
       " 'dbpedia_15635': 'writer',\n",
       " 'dbpedia_23187': 'scientist',\n",
       " 'dbpedia_13792': 'person',\n",
       " 'dbpedia_8800': 'plant',\n",
       " 'dbpedia_1532': 'televisionshow',\n",
       " 'dbpedia_21995': 'film',\n",
       " 'dbpedia_23060': 'informationappliance',\n",
       " 'dbpedia_15007': 'monarch',\n",
       " 'dbpedia_22836': 'comicscharacter',\n",
       " 'dbpedia_3468': 'single',\n",
       " 'dbpedia_939': 'disease',\n",
       " 'dbpedia_16195': 'mountain',\n",
       " 'dbpedia_5218': 'single',\n",
       " 'dbpedia_7780': 'historicplace',\n",
       " 'dbpedia_22484': 'fungus',\n",
       " 'dbpedia_10484': 'single',\n",
       " 'dbpedia_5872': 'building',\n",
       " 'dbpedia_7056': 'company',\n",
       " 'dbpedia_2857': 'castle',\n",
       " 'dbpedia_19392': 'book',\n",
       " 'dbpedia_3357': 'company',\n",
       " 'dbpedia_7028': 'beverage',\n",
       " 'dbpedia_13953': 'film',\n",
       " 'dbpedia_789': 'single',\n",
       " 'dbpedia_7755': 'officeholder',\n",
       " 'dbpedia_22187': 'song',\n",
       " 'dbpedia_3907': 'ncaateamseason',\n",
       " 'dbpedia_23064': 'writer',\n",
       " 'dbpedia_985': 'person',\n",
       " 'dbpedia_8208': 'insect',\n",
       " 'dbpedia_311': 'protectedarea',\n",
       " 'dbpedia_15039': 'mountain',\n",
       " 'dbpedia_9804': 'person',\n",
       " 'dbpedia_7913': 'athlete',\n",
       " 'dbpedia_23044': 'ncaateamseason',\n",
       " 'dbpedia_12632': 'election',\n",
       " 'dbpedia_20191': 'settlement',\n",
       " 'dbpedia_20479': 'militaryconflict',\n",
       " 'dbpedia_9678': 'person',\n",
       " 'dbpedia_17455': 'film',\n",
       " 'dbpedia_13648': 'song',\n",
       " 'dbpedia_2348': 'baseballplayer',\n",
       " 'dbpedia_16728': 'officeholder',\n",
       " 'dbpedia_14551': 'organisation',\n",
       " 'dbpedia_18590': 'building',\n",
       " 'dbpedia_4198': 'company',\n",
       " 'dbpedia_20599': 'person',\n",
       " 'dbpedia_14483': 'chemicalcompound',\n",
       " 'dbpedia_683': 'soccerplayer',\n",
       " 'dbpedia_15355': 'rugbyplayer',\n",
       " 'dbpedia_15391': 'film',\n",
       " 'dbpedia_18449': 'televisionshow',\n",
       " 'dbpedia_13709': 'album',\n",
       " 'dbpedia_6981': 'chemicalcompound',\n",
       " 'dbpedia_7869': 'film',\n",
       " 'dbpedia_584': 'settlement',\n",
       " 'dbpedia_7778': 'single',\n",
       " 'dbpedia_5953': 'soccerplayer',\n",
       " 'dbpedia_11539': 'company',\n",
       " 'dbpedia_1457': 'person',\n",
       " 'dbpedia_9470': 'videogame',\n",
       " 'dbpedia_8279': 'writer',\n",
       " 'dbpedia_19517': 'radiostation',\n",
       " 'dbpedia_15265': 'cricketer',\n",
       " 'dbpedia_1158': 'officeholder',\n",
       " 'dbpedia_22865': 'grandprix',\n",
       " 'dbpedia_16562': 'school',\n",
       " 'dbpedia_8610': 'aircraft',\n",
       " 'dbpedia_14097': 'single',\n",
       " 'dbpedia_14075': 'album',\n",
       " 'dbpedia_4942': 'rollercoaster',\n",
       " 'dbpedia_5291': 'academicjournal',\n",
       " 'dbpedia_14209': 'company',\n",
       " 'dbpedia_10058': 'village',\n",
       " 'dbpedia_11928': 'website',\n",
       " 'dbpedia_21947': 'road',\n",
       " 'dbpedia_17638': 'film',\n",
       " 'dbpedia_19686': 'election',\n",
       " 'dbpedia_14907': 'album',\n",
       " 'dbpedia_8711': 'person',\n",
       " 'dbpedia_6947': 'scientist',\n",
       " 'dbpedia_14395': 'politician',\n",
       " 'dbpedia_21905': 'militaryperson',\n",
       " 'dbpedia_16881': 'film',\n",
       " 'dbpedia_10676': 'building',\n",
       " 'dbpedia_13704': 'village',\n",
       " 'dbpedia_19256': 'governmentagency',\n",
       " 'dbpedia_18479': 'university',\n",
       " 'dbpedia_15847': 'album',\n",
       " 'dbpedia_13012': 'settlement',\n",
       " 'dbpedia_21988': 'person',\n",
       " 'dbpedia_20697': 'settlement',\n",
       " 'dbpedia_21863': 'person',\n",
       " 'dbpedia_701': 'airline',\n",
       " 'dbpedia_282': 'award',\n",
       " 'dbpedia_3050': 'university',\n",
       " 'dbpedia_14685': 'academicjournal',\n",
       " 'dbpedia_11552': 'ship',\n",
       " 'dbpedia_5256': 'videogame',\n",
       " 'dbpedia_14587': 'album',\n",
       " 'dbpedia_21811': 'religiousbuilding',\n",
       " 'dbpedia_8813': 'album',\n",
       " 'dbpedia_21370': 'writer',\n",
       " 'dbpedia_18641': 'insect',\n",
       " 'dbpedia_17834': 'ship',\n",
       " 'dbpedia_4770': 'book',\n",
       " 'dbpedia_4669': 'mollusca',\n",
       " 'dbpedia_22557': 'gaelicgamesplayer',\n",
       " 'dbpedia_11092': 'person',\n",
       " 'dbpedia_3649': 'scientist',\n",
       " 'dbpedia_14532': 'governmentagency',\n",
       " 'dbpedia_997': 'ethnicgroup',\n",
       " 'dbpedia_3591': 'album',\n",
       " 'dbpedia_1415': 'person',\n",
       " 'dbpedia_3336': 'americanfootballplayer',\n",
       " 'dbpedia_13091': 'software',\n",
       " 'dbpedia_3911': 'building',\n",
       " 'dbpedia_12703': 'tradeunion',\n",
       " 'dbpedia_9162': 'album',\n",
       " 'dbpedia_5526': 'single',\n",
       " 'dbpedia_12341': 'village',\n",
       " 'dbpedia_1336': 'chemicalcompound',\n",
       " 'dbpedia_7086': 'species',\n",
       " 'dbpedia_16994': 'company',\n",
       " 'dbpedia_13829': 'river',\n",
       " 'dbpedia_15822': 'film',\n",
       " 'dbpedia_16391': 'award',\n",
       " 'dbpedia_2896': 'bank',\n",
       " 'dbpedia_1811': 'fish',\n",
       " 'dbpedia_9298': 'software',\n",
       " 'dbpedia_12898': 'administrativeregion',\n",
       " 'dbpedia_19751': 'historicplace',\n",
       " 'dbpedia_19723': 'scientist',\n",
       " 'dbpedia_21655': 'philosopher',\n",
       " 'dbpedia_14187': 'year',\n",
       " 'dbpedia_325': 'insect',\n",
       " 'dbpedia_18524': 'film',\n",
       " 'dbpedia_15416': 'single',\n",
       " 'dbpedia_13814': 'person',\n",
       " 'dbpedia_14469': 'soccerclubseason',\n",
       " 'dbpedia_16539': 'book',\n",
       " 'dbpedia_13577': 'noble',\n",
       " 'dbpedia_261': 'protectedarea',\n",
       " 'dbpedia_21744': 'televisionshow',\n",
       " 'dbpedia_6145': 'officeholder',\n",
       " 'dbpedia_20146': 'band',\n",
       " 'dbpedia_17491': 'person',\n",
       " 'dbpedia_20881': 'officeholder',\n",
       " 'dbpedia_21312': 'river',\n",
       " 'dbpedia_1939': 'school',\n",
       " 'dbpedia_13155': 'newspaper',\n",
       " 'dbpedia_13587': 'album',\n",
       " 'dbpedia_15119': 'award',\n",
       " 'dbpedia_1306': 'videogame',\n",
       " 'dbpedia_10820': 'writer',\n",
       " 'dbpedia_633': 'plant',\n",
       " 'dbpedia_18381': 'settlement',\n",
       " 'dbpedia_3938': 'noble',\n",
       " 'dbpedia_2983': 'scientist',\n",
       " 'dbpedia_19613': 'person',\n",
       " 'dbpedia_3145': 'school',\n",
       " 'dbpedia_9155': 'person',\n",
       " 'dbpedia_9850': 'film',\n",
       " 'dbpedia_18340': 'officeholder',\n",
       " 'dbpedia_4495': 'person',\n",
       " 'dbpedia_12812': 'tennisplayer',\n",
       " 'dbpedia_654': 'chemicalcompound',\n",
       " 'dbpedia_1929': 'artist',\n",
       " 'dbpedia_4278': 'chemicalcompound',\n",
       " 'dbpedia_6504': 'school',\n",
       " 'dbpedia_15196': 'company',\n",
       " 'dbpedia_6342': 'settlement',\n",
       " 'dbpedia_7921': 'americanfootballplayer',\n",
       " 'dbpedia_10538': 'disease',\n",
       " 'dbpedia_7074': 'noble',\n",
       " 'dbpedia_20505': 'historicplace',\n",
       " 'dbpedia_14578': 'chemicalcompound',\n",
       " 'dbpedia_2716': 'militaryconflict',\n",
       " 'dbpedia_14042': 'film',\n",
       " 'dbpedia_3634': 'governmentagency',\n",
       " 'dbpedia_4160': 'website',\n",
       " 'dbpedia_23549': 'book',\n",
       " 'dbpedia_14644': 'chemicalcompound',\n",
       " 'dbpedia_16824': 'royalty',\n",
       " 'dbpedia_21456': 'company',\n",
       " 'dbpedia_21030': 'insect',\n",
       " 'dbpedia_22882': 'building',\n",
       " 'dbpedia_14870': 'enzyme',\n",
       " 'dbpedia_7862': 'ship',\n",
       " 'dbpedia_14766': 'athlete',\n",
       " 'dbpedia_21256': 'historicplace',\n",
       " 'dbpedia_12109': 'person',\n",
       " 'dbpedia_15588': 'film',\n",
       " 'dbpedia_16093': 'person',\n",
       " 'dbpedia_9493': 'organisation',\n",
       " 'dbpedia_18704': 'company',\n",
       " 'dbpedia_2770': 'software',\n",
       " 'dbpedia_9278': 'election',\n",
       " 'dbpedia_14009': 'person',\n",
       " 'dbpedia_6744': 'settlement',\n",
       " 'dbpedia_19462': 'person',\n",
       " 'dbpedia_21103': 'gridironfootballplayer',\n",
       " 'dbpedia_7440': 'food',\n",
       " 'dbpedia_16407': 'river',\n",
       " 'dbpedia_5212': 'river',\n",
       " 'dbpedia_5785': 'film',\n",
       " 'dbpedia_21722': 'company',\n",
       " 'dbpedia_20779': 'soccerplayer',\n",
       " 'dbpedia_20678': 'scientist',\n",
       " 'dbpedia_1742': 'person',\n",
       " 'dbpedia_690': 'book',\n",
       " 'dbpedia_10945': 'film',\n",
       " 'dbpedia_7872': 'book',\n",
       " 'dbpedia_22918': 'airline',\n",
       " 'dbpedia_4203': 'building',\n",
       " 'dbpedia_19958': 'film',\n",
       " 'dbpedia_4189': 'olympicevent',\n",
       " 'dbpedia_4028': 'person',\n",
       " 'dbpedia_8700': 'star',\n",
       " 'dbpedia_2847': 'band',\n",
       " 'dbpedia_8049': 'film',\n",
       " 'dbpedia_21967': 'bridge',\n",
       " 'dbpedia_3399': 'village',\n",
       " 'dbpedia_21299': 'building',\n",
       " 'dbpedia_120': 'company',\n",
       " 'dbpedia_407': 'politicalparty',\n",
       " 'dbpedia_6690': 'film',\n",
       " 'dbpedia_13695': 'planet',\n",
       " 'dbpedia_18497': 'book',\n",
       " 'dbpedia_10794': 'officeholder',\n",
       " 'dbpedia_20019': 'film',\n",
       " 'dbpedia_2831': 'settlement',\n",
       " 'dbpedia_11677': 'settlement',\n",
       " 'dbpedia_23492': 'film',\n",
       " 'dbpedia_3592': 'settlement',\n",
       " 'dbpedia_14197': 'person',\n",
       " 'dbpedia_11157': 'album',\n",
       " 'dbpedia_4321': 'writer',\n",
       " 'dbpedia_19189': 'building',\n",
       " 'dbpedia_16438': 'soccertournament',\n",
       " 'dbpedia_9460': 'album',\n",
       " 'dbpedia_16322': 'film',\n",
       " 'dbpedia_2268': 'person',\n",
       " 'dbpedia_1441': 'scientist',\n",
       " 'dbpedia_2325': 'chemicalcompound',\n",
       " 'dbpedia_8341': 'officeholder',\n",
       " 'dbpedia_14873': 'militaryperson',\n",
       " 'dbpedia_15469': 'film',\n",
       " 'dbpedia_14792': 'website',\n",
       " 'dbpedia_5465': 'building',\n",
       " 'dbpedia_3991': 'single',\n",
       " 'dbpedia_4127': 'album',\n",
       " 'dbpedia_4002': 'officeholder',\n",
       " 'dbpedia_725': 'governmentagency',\n",
       " 'dbpedia_14371': 'royalty',\n",
       " 'dbpedia_15690': 'organisation',\n",
       " 'dbpedia_10522': 'athlete',\n",
       " 'dbpedia_3988': 'single',\n",
       " 'dbpedia_13930': 'building',\n",
       " 'dbpedia_12118': 'officeholder',\n",
       " 'dbpedia_11658': 'settlement',\n",
       " 'dbpedia_3899': 'aircraft',\n",
       " 'dbpedia_15308': 'scientist',\n",
       " 'dbpedia_4393': 'single',\n",
       " 'dbpedia_14799': 'person',\n",
       " 'dbpedia_11083': 'organisation',\n",
       " 'dbpedia_4060': 'administrativeregion',\n",
       " 'dbpedia_14467': 'book',\n",
       " 'dbpedia_18405': 'aircraft',\n",
       " 'dbpedia_11014': 'radiostation',\n",
       " 'dbpedia_7146': 'chessplayer',\n",
       " 'dbpedia_10385': 'company',\n",
       " 'dbpedia_21133': 'organisation',\n",
       " 'dbpedia_2747': 'architect',\n",
       " 'dbpedia_9936': 'park',\n",
       " 'dbpedia_3980': 'railwayline',\n",
       " 'dbpedia_20435': 'televisionshow',\n",
       " 'dbpedia_11798': 'airport',\n",
       " 'dbpedia_12353': 'film',\n",
       " 'dbpedia_467': 'person',\n",
       " 'dbpedia_7274': 'single',\n",
       " 'dbpedia_7106': 'university',\n",
       " 'dbpedia_16325': 'company',\n",
       " 'dbpedia_17043': 'bank',\n",
       " 'dbpedia_15111': 'book',\n",
       " 'dbpedia_19182': 'baseballplayer',\n",
       " 'dbpedia_19886': 'food',\n",
       " 'dbpedia_12873': 'settlement',\n",
       " 'dbpedia_4143': 'drug',\n",
       " 'dbpedia_1217': 'person',\n",
       " 'dbpedia_8858': 'bridge',\n",
       " 'dbpedia_10605': 'book',\n",
       " 'dbpedia_20467': 'person',\n",
       " 'dbpedia_17975': 'book',\n",
       " 'dbpedia_2592': 'militaryunit',\n",
       " 'dbpedia_7258': 'tennisplayer',\n",
       " 'dbpedia_21267': 'settlement',\n",
       " 'dbpedia_22110': 'programminglanguage',\n",
       " 'dbpedia_10072': 'insect',\n",
       " 'dbpedia_3294': 'scientist',\n",
       " 'dbpedia_8458': 'programminglanguage',\n",
       " 'dbpedia_15076': 'person',\n",
       " 'dbpedia_2330': 'film',\n",
       " 'dbpedia_1420': 'album',\n",
       " 'dbpedia_16288': 'website',\n",
       " 'dbpedia_7358': 'website',\n",
       " 'dbpedia_9957': 'administrativeregion',\n",
       " 'dbpedia_4751': 'book',\n",
       " 'dbpedia_3454': 'administrativeregion',\n",
       " 'dbpedia_15303': 'school',\n",
       " 'dbpedia_4941': 'soccerclub',\n",
       " 'dbpedia_4973': 'river',\n",
       " 'dbpedia_15209': 'musicalartist',\n",
       " 'dbpedia_5372': 'classicalmusiccomposition',\n",
       " 'dbpedia_14977': 'televisionshow',\n",
       " 'dbpedia_19948': 'televisionstation',\n",
       " 'dbpedia_23137': 'person',\n",
       " 'dbpedia_4704': 'album',\n",
       " 'dbpedia_16000': 'village',\n",
       " 'dbpedia_6516': 'film',\n",
       " 'dbpedia_5010': 'album',\n",
       " 'dbpedia_14439': 'artificialsatellite',\n",
       " 'dbpedia_23553': 'single',\n",
       " 'dbpedia_13437': 'settlement',\n",
       " 'dbpedia_8902': 'film',\n",
       " 'dbpedia_15610': 'album',\n",
       " 'dbpedia_6818': 'disease',\n",
       " 'dbpedia_22391': 'musicalartist',\n",
       " 'dbpedia_892': 'musicalartist',\n",
       " 'dbpedia_11938': 'film',\n",
       " 'dbpedia_6983': 'album',\n",
       " 'dbpedia_11085': 'scientist',\n",
       " 'dbpedia_5928': 'album',\n",
       " 'dbpedia_989': 'album',\n",
       " 'dbpedia_16699': 'radiostation',\n",
       " 'dbpedia_12407': 'protein',\n",
       " 'dbpedia_19969': 'film',\n",
       " 'dbpedia_11319': 'protein',\n",
       " 'dbpedia_6027': 'fish',\n",
       " 'dbpedia_3637': 'lake',\n",
       " 'dbpedia_10157': 'book',\n",
       " 'dbpedia_22609': 'sportsteammember',\n",
       " 'dbpedia_649': 'writer',\n",
       " 'dbpedia_10342': 'person',\n",
       " 'dbpedia_12084': 'soccerclub',\n",
       " 'dbpedia_5200': 'locomotive',\n",
       " ...}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_type_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
